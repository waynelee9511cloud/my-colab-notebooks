{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waynelee9511cloud/my-colab-notebooks/blob/dm-work/ePRO%E5%88%86%E6%9E%90%E7%A8%8B%E5%BC%8F_v3_2_%E6%8E%92%E5%88%97%E5%A5%BDexcel%E5%B7%A5%E4%BD%9C%E8%A1%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XryOZnNy-ldW"
      },
      "outputs": [],
      "source": [
        "#@title å®‰è£å¿…è¦å¥—ä»¶\n",
        "!pip install pandas openpyxl -q\n",
        "print('âœ… å¥—ä»¶å®‰è£å®Œæˆï¼')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3jR6lIJ-ldW"
      },
      "outputs": [],
      "source": [
        "#@title åŸ·è¡ŒePRO å¸³è™Ÿç®¡ç†ç›£æ§ç¨‹å¼ - v3.2 (å«å•å·å¡«å¯«åˆ†æåŠç‹€æ…‹ç‰¹æ®Šè¦å‰‡)\n",
        "\n",
        "# åŸ·è¡Œä¸‹æ–¹ç¨‹å¼ç¢¼å¾Œï¼Œç³»çµ±æœƒè¦æ±‚æ‚¨ä¸Šå‚³æª”æ¡ˆï¼š\n",
        "# - crf_data.xlsxï¼ˆéœ€åŒ…å« SFã€DSã€SV å·¥ä½œè¡¨ï¼‰\n",
        "# - epro_data.xlsxï¼ˆéœ€åŒ…å« epro å·¥ä½œè¡¨ï¼‰\n",
        "# - subject_list.xlsxï¼ˆéœ€åŒ…å« Screening No. å’Œ Status æ¬„ä½ï¼‰\n",
        "# - epro_content_data.xlsxï¼ˆéœ€åŒ…å« BGTRT1ã€BGTRT2ã€NRS1ã€NRS2 å·¥ä½œè¡¨ï¼‰\n",
        "# å®Œæˆå¾Œæœƒè‡ªå‹•ç”¢ç”Ÿä¸¦ä¸‹è¼‰ ePROåˆ†æçµæœ_å®Œæ•´å ±å‘Š.xlsx\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ==================== è¨­å®š ====================\n",
        "TODAY = pd.Timestamp('2025-11-10')\n",
        "DELAY_THRESHOLD = 7  # å»¶é²é–¾å€¼ï¼ˆå¤©æ•¸ï¼‰\n",
        "CUTOFF_DAYS = 30  # V1/V2å¾Œè¶…éå¤šå°‘å¤©éœ€è¦æª¢æŸ¥\n",
        "\n",
        "# ==================== æ’é™¤åå–® ====================\n",
        "# å¦‚æœæœ‰éœ€è¦æ’é™¤çš„å—è©¦è€…ï¼Œè«‹åœ¨ä¸‹æ–¹åˆ—è¡¨ä¸­æ–°å¢ Screening Number\n",
        "EXCLUDE_SUBJECTS = [\n",
        "    'ST03008',  # èª¤æ“ä½œï¼Œä¸ç´å…¥åˆ†æ\n",
        "    # å¯åœ¨æ­¤æ–°å¢æ›´å¤šè¦æ’é™¤çš„å—è©¦è€… Screening Number\n",
        "]\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ğŸ¥ è‡¨åºŠè©¦é©— ePRO å¸³è™Ÿç®¡ç†ç›£æ§ç¨‹å¼ï¼ˆColab ç‰ˆæœ¬ v3.2 - å«å•å·åˆ†æåŠç‹€æ…‹ç‰¹æ®Šè¦å‰‡ï¼‰\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nğŸ“… åˆ†æåŸºæº–æ—¥æœŸï¼š{TODAY.strftime('%Y-%m-%d')}\")\n",
        "print(f\"âš ï¸  å»¶é²é–¾å€¼ï¼šè¶…é {DELAY_THRESHOLD} å¤©\")\n",
        "print(f\"âš ï¸  V1/V2æª¢æŸ¥é–¾å€¼ï¼šè¶…é {CUTOFF_DAYS} å¤©\")\n",
        "if EXCLUDE_SUBJECTS:\n",
        "    print(f\"ğŸš« æ’é™¤å—è©¦è€…ï¼š{', '.join(EXCLUDE_SUBJECTS)}\")\n",
        "print(\"\\né–‹å§‹åŸ·è¡Œ...\\n\")\n",
        "\n",
        "\n",
        "def read_epro_content_data(content_file):\n",
        "    \"\"\"è®€å– ePRO å•å·å¡«å¯«å…§å®¹æ•¸æ“š\"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"ğŸ“ æ­¥é©Ÿ 0ï¼šè®€å– ePRO å•å·å¡«å¯«å…§å®¹\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # è®€å–å››å€‹å·¥ä½œè¡¨\n",
        "    bgtrt1 = pd.read_excel(content_file, sheet_name='BGTRT1')\n",
        "    bgtrt2 = pd.read_excel(content_file, sheet_name='BGTRT2')\n",
        "    nrs1 = pd.read_excel(content_file, sheet_name='NRS1')\n",
        "    nrs2 = pd.read_excel(content_file, sheet_name='NRS2')\n",
        "\n",
        "    print(f\"âœ“ BGTRT1ï¼š{len(bgtrt1)} ç­†\")\n",
        "    print(f\"âœ“ BGTRT2ï¼š{len(bgtrt2)} ç­†\")\n",
        "    print(f\"âœ“ NRS1ï¼š{len(nrs1)} ç­†\")\n",
        "    print(f\"âœ“ NRS2ï¼š{len(nrs2)} ç­†\")\n",
        "\n",
        "    # åˆä½µ Background Treatment è³‡æ–™ï¼ˆBGTRT1 + BGTRT2ï¼‰\n",
        "    bgtrt_all = pd.concat([bgtrt1, bgtrt2], ignore_index=True)\n",
        "    bgtrt_all['Date of record'] = pd.to_datetime(bgtrt_all['Date of record'], errors='coerce').dt.date\n",
        "    bgtrt_all = bgtrt_all[bgtrt_all['Date of record'].notna()]\n",
        "\n",
        "    # åˆä½µ NRS è³‡æ–™ï¼ˆNRS1 + NRS2ï¼‰\n",
        "    nrs_all = pd.concat([nrs1, nrs2], ignore_index=True)\n",
        "    nrs_all['Date of record'] = pd.to_datetime(nrs_all['Date of record'], errors='coerce').dt.date\n",
        "    nrs_all = nrs_all[nrs_all['Date of record'].notna()]\n",
        "\n",
        "    print(f\"\\nâœ“ åˆä½µå¾Œ Background Treatmentï¼š{len(bgtrt_all)} ç­†æœ‰æ•ˆè¨˜éŒ„\")\n",
        "    print(f\"âœ“ åˆä½µå¾Œ NRSï¼š{len(nrs_all)} ç­†æœ‰æ•ˆè¨˜éŒ„\")\n",
        "\n",
        "    # æ•´ç†æ¯å€‹å—è©¦è€…çš„å¡«å¯«æ—¥æœŸ\n",
        "    def summarize_questionnaire_dates(df, questionnaire_name):\n",
        "        \"\"\"æ•´ç†å•å·å¡«å¯«æ—¥æœŸæ‘˜è¦\"\"\"\n",
        "        summary = {}\n",
        "\n",
        "        for sn in df['Screening Number'].unique():\n",
        "            sn_data = df[df['Screening Number'] == sn].copy()\n",
        "            dates = sorted(sn_data['Date of record'].unique())\n",
        "\n",
        "            if len(dates) > 0:\n",
        "                start_date = dates[0]\n",
        "                end_date = dates[-1]\n",
        "\n",
        "                # è¨ˆç®—æ‡‰è©²è¦æœ‰çš„æ‰€æœ‰æ—¥æœŸ\n",
        "                all_dates = pd.date_range(start=start_date, end=end_date, freq='D').date\n",
        "                filled_dates = set(dates)\n",
        "                missing_dates = sorted([d for d in all_dates if d not in filled_dates])\n",
        "\n",
        "                summary[sn] = {\n",
        "                    'questionnaire': questionnaire_name,\n",
        "                    'start_date': start_date,\n",
        "                    'end_date': end_date,\n",
        "                    'filled_dates': dates,\n",
        "                    'filled_count': len(dates),\n",
        "                    'missing_dates': missing_dates,\n",
        "                    'missing_count': len(missing_dates)\n",
        "                }\n",
        "\n",
        "        return summary\n",
        "\n",
        "    bgtrt_summary = summarize_questionnaire_dates(bgtrt_all, 'Background Treatment')\n",
        "    nrs_summary = summarize_questionnaire_dates(nrs_all, 'NRS')\n",
        "\n",
        "    print(f\"\\nâœ“ Background Treatment å•å·ï¼š{len(bgtrt_summary)} ä½å—è©¦è€…æœ‰å¡«å¯«è¨˜éŒ„\")\n",
        "    print(f\"âœ“ NRS å•å·ï¼š{len(nrs_summary)} ä½å—è©¦è€…æœ‰å¡«å¯«è¨˜éŒ„\")\n",
        "\n",
        "    return bgtrt_all, nrs_all, bgtrt_summary, nrs_summary\n",
        "\n",
        "\n",
        "def analyze_questionnaire_compliance(bgtrt_summary, nrs_summary, subject_list, sf, sv):\n",
        "    \"\"\"åˆ†æå•å·å¡«å¯«åˆè¦æ€§\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ğŸ“Š æ­¥é©Ÿ 0.5ï¼šåˆ†æå•å·å¡«å¯«åˆè¦æ€§\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # æº–å‚™ subject_list è³‡æ–™\n",
        "    subject_list = subject_list.rename(columns={'Screening No.': 'Screening Number'})\n",
        "    subject_list['First visit date'] = pd.to_datetime(subject_list['First visit date'], errors='coerce').dt.date\n",
        "    subject_list['Last visit date'] = pd.to_datetime(subject_list['Last visit date'], errors='coerce').dt.date\n",
        "\n",
        "    # åˆ†æçµæœ\n",
        "    compliance_results = []\n",
        "\n",
        "    for _, row in subject_list.iterrows():\n",
        "        sn = row['Screening Number']\n",
        "        first_visit = row['First visit date']\n",
        "        last_visit = row['Last visit']\n",
        "        last_visit_date = row['Last visit date']\n",
        "        status = row.get('Status', '')  # å–å¾— Status æ¬„ä½\n",
        "\n",
        "        if pd.isna(first_visit):\n",
        "            continue\n",
        "\n",
        "        # æ±ºå®šæ‡‰è©²å¡«å¯«å•å·çš„æ—¥æœŸå€é–“\n",
        "        expected_end_date = None\n",
        "\n",
        "        # è¦å‰‡1: Screening Failure ç‹€æ…‹çš„ç‰¹æ®Šè™•ç†\n",
        "        if status == 'Screening Failure':\n",
        "            # å˜—è©¦å¾ SF å·¥ä½œè¡¨å–å¾— Date of screening failure\n",
        "            sf_date = None\n",
        "            if not sf.empty and 'Date of screening failure' in sf.columns:\n",
        "                sf_record = sf[sf['Screening Number'] == sn]\n",
        "                if not sf_record.empty:\n",
        "                    sf_date = sf_record.iloc[0]['Date of screening failure']\n",
        "\n",
        "            if pd.notna(sf_date):\n",
        "                # æœ‰ Date of screening failureï¼Œä½¿ç”¨è©²æ—¥æœŸ\n",
        "                expected_end_date = sf_date\n",
        "            else:\n",
        "                # æ²’æœ‰ Date of screening failureï¼Œå– V1(D-28 to -1) çš„ Visit Date + 27å¤©\n",
        "                if not sv.empty and 'Visit Date' in sv.columns and 'VISIT' in sv.columns:\n",
        "                    v1_record = sv[(sv['Screening Number'] == sn) & (sv['VISIT'] == 'V1(D-28 to -1)')]\n",
        "                    if not v1_record.empty:\n",
        "                        v1_date = v1_record.iloc[0]['Visit Date']\n",
        "                        if pd.notna(v1_date):\n",
        "                            expected_end_date = v1_date + timedelta(days=27)\n",
        "\n",
        "        # è¦å‰‡2: Screening ç‹€æ…‹çš„ç‰¹æ®Šè™•ç†\n",
        "        elif status == 'Screening':\n",
        "            # è¨ˆç®— First visit date è·é›¢ä»Šå¤©çš„å¤©æ•¸\n",
        "            days_since_first_visit = (TODAY.date() - first_visit).days\n",
        "\n",
        "            if days_since_first_visit > 28:\n",
        "                # è¶…é28å¤©ï¼Œä½¿ç”¨ First visit date + 27å¤©\n",
        "                expected_end_date = first_visit + timedelta(days=27)\n",
        "            else:\n",
        "                # æ²’æœ‰è¶…é28å¤©ï¼Œä½¿ç”¨ä»Šå¤©\n",
        "                expected_end_date = TODAY.date()\n",
        "\n",
        "        # åŸæœ‰è¦å‰‡: å…¶ä»–ç‹€æ…‹çš„è™•ç†\n",
        "        if expected_end_date is None:\n",
        "            if pd.notna(last_visit) and 'V9' in str(last_visit).upper() or 'EOS' in str(last_visit).upper():\n",
        "                # Last visit æ˜¯ V9/EOSï¼Œç”¨ Last visit date\n",
        "                if pd.notna(last_visit_date):\n",
        "                    expected_end_date = last_visit_date\n",
        "                else:\n",
        "                    expected_end_date = TODAY.date()\n",
        "            else:\n",
        "                # Last visit ä¸æ˜¯ V9/EOSï¼Œç”¨ TODAY\n",
        "                expected_end_date = TODAY.date()\n",
        "\n",
        "        expected_start_date = first_visit\n",
        "\n",
        "        # è¨ˆç®—æ‡‰è©²å¡«å¯«çš„æ‰€æœ‰æ—¥æœŸ\n",
        "        expected_dates = set(pd.date_range(start=expected_start_date, end=expected_end_date, freq='D').date)\n",
        "\n",
        "        # æª¢æŸ¥ Background Treatment\n",
        "        bgtrt_info = bgtrt_summary.get(sn, {})\n",
        "        if bgtrt_info:\n",
        "            bgtrt_filled = set(bgtrt_info['filled_dates'])\n",
        "            bgtrt_missing = expected_dates - bgtrt_filled\n",
        "            bgtrt_extra = bgtrt_filled - expected_dates\n",
        "        else:\n",
        "            bgtrt_filled = set()\n",
        "            bgtrt_missing = expected_dates\n",
        "            bgtrt_extra = set()\n",
        "\n",
        "        # æª¢æŸ¥ NRS\n",
        "        nrs_info = nrs_summary.get(sn, {})\n",
        "        if nrs_info:\n",
        "            nrs_filled = set(nrs_info['filled_dates'])\n",
        "            nrs_missing = expected_dates - nrs_filled\n",
        "            nrs_extra = nrs_filled - expected_dates\n",
        "        else:\n",
        "            nrs_filled = set()\n",
        "            nrs_missing = expected_dates\n",
        "            nrs_extra = set()\n",
        "\n",
        "        # è¨˜éŒ„çµæœ\n",
        "        result = {\n",
        "            'Screening Number': sn,\n",
        "            'First visit date': expected_start_date,\n",
        "            'Last visit': last_visit,\n",
        "            'Last visit date': last_visit_date,\n",
        "            'Expected end date': expected_end_date,\n",
        "            'Expected days': len(expected_dates),\n",
        "\n",
        "            # Background Treatment\n",
        "            'BGTRT filled days': len(bgtrt_filled),\n",
        "            'BGTRT missing days': len(bgtrt_missing),\n",
        "            'BGTRT missing dates': sorted(list(bgtrt_missing)) if bgtrt_missing else [],\n",
        "            'BGTRT extra days': len(bgtrt_extra),\n",
        "            'BGTRT extra dates': sorted(list(bgtrt_extra)) if bgtrt_extra else [],\n",
        "            'BGTRT compliance': f\"{len(bgtrt_filled)/len(expected_dates)*100:.1f}%\" if expected_dates else \"N/A\",\n",
        "\n",
        "            # NRS\n",
        "            'NRS filled days': len(nrs_filled),\n",
        "            'NRS missing days': len(nrs_missing),\n",
        "            'NRS missing dates': sorted(list(nrs_missing)) if nrs_missing else [],\n",
        "            'NRS extra days': len(nrs_extra),\n",
        "            'NRS extra dates': sorted(list(nrs_extra)) if nrs_extra else [],\n",
        "            'NRS compliance': f\"{len(nrs_filled)/len(expected_dates)*100:.1f}%\" if expected_dates else \"N/A\"\n",
        "        }\n",
        "\n",
        "        compliance_results.append(result)\n",
        "\n",
        "    compliance_df = pd.DataFrame(compliance_results)\n",
        "\n",
        "    # çµ±è¨ˆ\n",
        "    print(f\"\\nâœ“ åˆ†æå®Œæˆï¼š{len(compliance_df)} ä½å—è©¦è€…\")\n",
        "\n",
        "    # æ‰¾å‡ºæœ‰å•é¡Œçš„å—è©¦è€…\n",
        "    bgtrt_issues = compliance_df[compliance_df['BGTRT missing days'] > 0]\n",
        "    nrs_issues = compliance_df[compliance_df['NRS missing days'] > 0]\n",
        "    bgtrt_extra_issues = compliance_df[compliance_df['BGTRT extra days'] > 0]\n",
        "    nrs_extra_issues = compliance_df[compliance_df['NRS extra days'] > 0]\n",
        "\n",
        "    print(f\"\\nğŸ“Š å•å·å¡«å¯«æƒ…æ³çµ±è¨ˆï¼š\")\n",
        "    print(f\"   Background Treatment æœ‰ç¼ºæ¼ï¼š{len(bgtrt_issues)} ä½\")\n",
        "    print(f\"   NRS æœ‰ç¼ºæ¼ï¼š{len(nrs_issues)} ä½\")\n",
        "    print(f\"   Background Treatment æœ‰å¤šå¡«ï¼š{len(bgtrt_extra_issues)} ä½\")\n",
        "    print(f\"   NRS æœ‰å¤šå¡«ï¼š{len(nrs_extra_issues)} ä½\")\n",
        "\n",
        "    return compliance_df, bgtrt_issues, nrs_issues, bgtrt_extra_issues, nrs_extra_issues\n",
        "\n",
        "\n",
        "def read_crf_data(crf_file):\n",
        "    \"\"\"è®€å– CRF æ•¸æ“š\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ğŸ“ æ­¥é©Ÿ 1ï¼šè®€å– CRF æ•¸æ“š\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # è®€å– SF (Screening Failure)\n",
        "    sf = pd.DataFrame()\n",
        "    if 'SF' in pd.ExcelFile(crf_file).sheet_names:\n",
        "        sf = pd.read_excel(crf_file, sheet_name='SF')\n",
        "        if 'Date of screening failure' in sf.columns:\n",
        "            sf['Date of screening failure'] = pd.to_datetime(sf['Date of screening failure'], errors='coerce').dt.date\n",
        "        print(f\"âœ“ SF å·¥ä½œè¡¨ï¼š{len(sf)} ç­†\")\n",
        "\n",
        "    # è®€å– DS (Disposition)\n",
        "    ds = pd.DataFrame()\n",
        "    if 'DS' in pd.ExcelFile(crf_file).sheet_names:\n",
        "        ds = pd.read_excel(crf_file, sheet_name='DS')\n",
        "        if 'Date of completion/ Early Termination/ Withdrawal' in ds.columns:\n",
        "            ds['Date of completion/ Early Termination/ Withdrawal'] = pd.to_datetime(\n",
        "                ds['Date of completion/ Early Termination/ Withdrawal'], errors='coerce'\n",
        "            ).dt.date\n",
        "        print(f\"âœ“ DS å·¥ä½œè¡¨ï¼š{len(ds)} ç­†\")\n",
        "\n",
        "    # è®€å– SV (Study Visits)\n",
        "    sv = pd.DataFrame()\n",
        "    if 'SV' in pd.ExcelFile(crf_file).sheet_names:\n",
        "        sv = pd.read_excel(crf_file, sheet_name='SV')\n",
        "        if 'Visit Date' in sv.columns:\n",
        "            sv['Visit Date'] = pd.to_datetime(sv['Visit Date'], errors='coerce').dt.date\n",
        "        print(f\"âœ“ SV å·¥ä½œè¡¨ï¼š{len(sv)} ç­†\")\n",
        "\n",
        "    return sf, ds, sv\n",
        "\n",
        "\n",
        "def read_epro_data(epro_file):\n",
        "    \"\"\"è®€å– ePRO æ•¸æ“š\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ğŸ“ æ­¥é©Ÿ 2ï¼šè®€å– ePRO æ•¸æ“š\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    epro = pd.read_excel(epro_file, sheet_name='epro')\n",
        "    print(f\"âœ“ åŸå§‹æ•¸æ“šï¼š{len(epro)} ç­†\")\n",
        "    print(f\"   åŸå§‹æ¬„ä½ï¼š{epro.columns.tolist()}\")\n",
        "\n",
        "    # å»ºç«‹æ¬„ä½æ˜ å°„å­—å…¸ï¼ˆæ”¯æ´å¤šç¨®å¯èƒ½çš„æ¬„ä½åç¨±ï¼‰\n",
        "    column_mapping = {}\n",
        "\n",
        "    # Subject/Screening Number æ¬„ä½\n",
        "    for col in epro.columns:\n",
        "        if col.strip().lower() in ['subject', 'screening number', 'screening no.', 'screening no']:\n",
        "            column_mapping[col] = 'Screening Number'\n",
        "            break\n",
        "\n",
        "    # Date/Time æ¬„ä½\n",
        "    for col in epro.columns:\n",
        "        col_lower = col.lower().strip()\n",
        "        if ('date' in col_lower and 'time' in col_lower) or col_lower == 'date/time':\n",
        "            column_mapping[col] = 'epro_date_time'\n",
        "            break\n",
        "\n",
        "    # æª¢æŸ¥æ˜¯å¦æ‰¾åˆ°å¿…è¦çš„æ¬„ä½\n",
        "    if 'Screening Number' not in column_mapping.values():\n",
        "        raise ValueError(f\"âŒ æ‰¾ä¸åˆ° Subject æˆ– Screening Number æ¬„ä½ã€‚å¯ç”¨æ¬„ä½ï¼š{epro.columns.tolist()}\")\n",
        "    if 'epro_date_time' not in column_mapping.values():\n",
        "        raise ValueError(f\"âŒ æ‰¾ä¸åˆ° Date/Time æ¬„ä½ã€‚å¯ç”¨æ¬„ä½ï¼š{epro.columns.tolist()}\")\n",
        "\n",
        "    # é‡æ–°å‘½åæ¬„ä½\n",
        "    epro = epro.rename(columns=column_mapping)\n",
        "    print(f\"   é‡æ–°å‘½åå¾Œæ¬„ä½ï¼š{epro.columns.tolist()}\")\n",
        "\n",
        "    # é©—è­‰é‡æ–°å‘½åæˆåŠŸ\n",
        "    if 'epro_date_time' not in epro.columns or 'Screening Number' not in epro.columns:\n",
        "        raise ValueError(f\"âŒ é‡æ–°å‘½åå¤±æ•—ï¼ç•¶å‰æ¬„ä½ï¼š{epro.columns.tolist()}\")\n",
        "\n",
        "    # æ¸…ç†æ™‚é–“æ ¼å¼\n",
        "    def clean_datetime(dt_str):\n",
        "        if pd.isna(dt_str):\n",
        "            return None\n",
        "        try:\n",
        "            dt_str = str(dt_str).split('(')[0].strip()\n",
        "            dt = pd.to_datetime(dt_str)\n",
        "            return dt.date()  # åªä¿ç•™æ—¥æœŸ\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    epro['epro_date'] = epro['epro_date_time'].apply(clean_datetime)\n",
        "\n",
        "    # æ³¨æ„ï¼šåŸå§‹æ•¸æ“šä¸­Statuså¯èƒ½æ‹¼å¯«ç‚º\"Nomal\"\n",
        "    epro['Status'] = epro['Status'].str.strip()\n",
        "    epro.loc[epro['Status'] == 'Nomal', 'Status'] = 'Normal'\n",
        "\n",
        "    # æœ€æ–°ç‹€æ…‹ï¼ˆNormalæˆ–Expiredï¼‰\n",
        "    epro_latest = epro.sort_values('epro_date_time', ascending=False).groupby('Screening Number').first().reset_index()\n",
        "    print(f\"âœ“ æœ€æ–°ç‹€æ…‹ï¼š{len(epro_latest)} ä½å—è©¦è€…\")\n",
        "    print(f\"   - Normal: {len(epro_latest[epro_latest['Status'] == 'Normal'])}\")\n",
        "    print(f\"   - Expired: {len(epro_latest[epro_latest['Status'] == 'Expired'])}\")\n",
        "\n",
        "    # Expired æ—¥æœŸ\n",
        "    epro_expired = epro[epro['Status'] == 'Expired'][['Screening Number', 'epro_date']].copy()\n",
        "    epro_expired = epro_expired.rename(columns={'epro_date': 'epro_expired_date'})\n",
        "    print(f\"âœ“ Expired è¨˜éŒ„ï¼š{len(epro_expired)} ç­†\")\n",
        "\n",
        "    # Normal æ—¥æœŸï¼ˆé–‹å¸³æ—¥æœŸï¼‰- ä¿®æ­£ï¼šå–ç¬¬ä¸€å€‹ Normal ç‹€æ…‹çš„æ—¥æœŸ\n",
        "    epro_normal = epro[epro['Status'] == 'Normal'].sort_values('epro_date_time').groupby('Screening Number').first().reset_index()\n",
        "    epro_normal = epro_normal[['Screening Number', 'epro_date']].copy()\n",
        "    epro_normal = epro_normal.rename(columns={'epro_date': 'epro_normal_date'})\n",
        "    print(f\"âœ“ Normal è¨˜éŒ„ï¼ˆç¬¬ä¸€æ¬¡é–‹å¸³ï¼‰ï¼š{len(epro_normal)} ç­†\")\n",
        "\n",
        "    return epro_latest, epro_expired, epro_normal\n",
        "\n",
        "\n",
        "def process_sv_data(sv):\n",
        "    \"\"\"è™•ç†SVæ•¸æ“šï¼Œæå–V1å’Œæœ€å¾Œvisit\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ğŸ“ æ­¥é©Ÿ 3ï¼šè™•ç† Visit æ•¸æ“š\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    if sv.empty:\n",
        "        print(\"âš ï¸ æ²’æœ‰SVæ•¸æ“š\")\n",
        "        return pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "    # æå–V1æ—¥æœŸ\n",
        "    v1 = sv[sv['VISIT'].str.contains('V1', case=False, na=False)].copy()\n",
        "    v1 = v1.sort_values('Visit Date').groupby('Screening Number').first().reset_index()\n",
        "    v1 = v1[['Screening Number', 'Visit Date']].rename(columns={'Visit Date': 'V1_date'})\n",
        "    print(f\"âœ“ V1 è¨˜éŒ„ï¼š{len(v1)} ä½å—è©¦è€…\")\n",
        "\n",
        "    # æ‰¾å‡ºæ¯å€‹å—è©¦è€…çš„æœ€å¾Œvisit\n",
        "    sv_sorted = sv.sort_values(['Screening Number', 'Visit Date'])\n",
        "    last_visit = sv_sorted.groupby('Screening Number').last().reset_index()\n",
        "    last_visit = last_visit[['Screening Number', 'VISIT', 'Visit Date']].rename(columns={\n",
        "        'VISIT': 'last_visit',\n",
        "        'Visit Date': 'last_visit_date'\n",
        "    })\n",
        "    print(f\"âœ“ æœ€å¾Œ Visit è¨˜éŒ„ï¼š{len(last_visit)} ä½å—è©¦è€…\")\n",
        "\n",
        "    return v1, last_visit\n",
        "\n",
        "\n",
        "def read_subject_list(subject_list_file):\n",
        "    \"\"\"è®€å– Subject Listï¼ˆè©¦é©—ç‹€æ…‹ï¼‰\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ğŸ“ æ­¥é©Ÿ 3.5ï¼šè®€å– Subject Listï¼ˆè©¦é©—ç‹€æ…‹ï¼‰\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    try:\n",
        "        subject_list = pd.read_excel(subject_list_file)\n",
        "\n",
        "        # é¸å–éœ€è¦çš„æ¬„ä½ï¼Œä¸¦é‡æ–°å‘½åä»¥çµ±ä¸€\n",
        "        if 'Screening No.' in subject_list.columns and 'Status' in subject_list.columns:\n",
        "            status_data = subject_list[['Screening No.', 'Status']].copy()\n",
        "            status_data = status_data.rename(columns={\n",
        "                'Screening No.': 'Screening Number',\n",
        "                'Status': 'è©¦é©—ç‹€æ…‹'\n",
        "            })\n",
        "            print(f\"âœ“ Subject Listï¼š{len(status_data)} ç­†\")\n",
        "            print(f\"   è©¦é©—ç‹€æ…‹åˆ†å¸ƒï¼š\")\n",
        "            for status, count in status_data['è©¦é©—ç‹€æ…‹'].value_counts().head(5).items():\n",
        "                print(f\"      - {status}: {count}\")\n",
        "            return status_data, subject_list\n",
        "        else:\n",
        "            print(\"âš ï¸ Subject List ç¼ºå°‘å¿…è¦æ¬„ä½\")\n",
        "            return pd.DataFrame(columns=['Screening Number', 'è©¦é©—ç‹€æ…‹']), subject_list\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ ç„¡æ³•è®€å– Subject Listï¼š{e}\")\n",
        "        return pd.DataFrame(columns=['Screening Number', 'è©¦é©—ç‹€æ…‹']), pd.DataFrame()\n",
        "\n",
        "\n",
        "def merge_all_data(sf, ds, sv, epro_latest, epro_expired, epro_normal, subject_status):\n",
        "    \"\"\"åˆä½µæ‰€æœ‰æ•¸æ“š\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ğŸ”— æ­¥é©Ÿ 4ï¼šåˆä½µæ•¸æ“š\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # è™•ç†SF\n",
        "    sf_data = sf[['Screening Number', 'Date of screening failure']].copy() if not sf.empty else pd.DataFrame(columns=['Screening Number', 'Date of screening failure'])\n",
        "    sf_data['exit_reason'] = 'SF'\n",
        "    sf_data = sf_data.rename(columns={'Date of screening failure': 'SF_or_EOS_date'})\n",
        "\n",
        "    # è™•ç†DS\n",
        "    ds_data = ds[['Screening Number', 'Date of completion/ Early Termination/ Withdrawal']].copy() if not ds.empty else pd.DataFrame(columns=['Screening Number', 'Date of completion/ Early Termination/ Withdrawal'])\n",
        "    ds_data['exit_reason'] = 'EOS'\n",
        "    ds_data = ds_data.rename(columns={'Date of completion/ Early Termination/ Withdrawal': 'SF_or_EOS_date'})\n",
        "\n",
        "    # åˆä½µSFå’ŒDS\n",
        "    crf_combined = pd.concat([sf_data, ds_data], ignore_index=True)\n",
        "    print(f\"âœ“ CRF æ•¸æ“šï¼š{len(crf_combined)} ç­†ï¼ˆSF: {len(sf_data)}, EOS: {len(ds_data)}ï¼‰\")\n",
        "\n",
        "    # è™•ç†SVæ•¸æ“š\n",
        "    v1_data, last_visit_data = process_sv_data(sv)\n",
        "\n",
        "    # åˆä½µæ‰€æœ‰æ•¸æ“š\n",
        "    result = epro_latest[['Screening Number', 'Status', 'epro_date']].copy()\n",
        "    result = result.rename(columns={'epro_date': 'epro_latest_date'})\n",
        "\n",
        "    # åˆä½µCRFæ•¸æ“š\n",
        "    result = result.merge(crf_combined, on='Screening Number', how='left')\n",
        "\n",
        "    # åˆä½µExpiredæ—¥æœŸ\n",
        "    result = result.merge(epro_expired, on='Screening Number', how='left')\n",
        "\n",
        "    # åˆä½µNormalæ—¥æœŸï¼ˆé–‹å¸³æ—¥æœŸï¼‰\n",
        "    result = result.merge(epro_normal, on='Screening Number', how='left')\n",
        "\n",
        "    # åˆä½µV1æ•¸æ“š\n",
        "    result = result.merge(v1_data, on='Screening Number', how='left')\n",
        "\n",
        "    # åˆä½µæœ€å¾Œvisitæ•¸æ“š\n",
        "    result = result.merge(last_visit_data, on='Screening Number', how='left')\n",
        "\n",
        "    # åˆä½µè©¦é©—ç‹€æ…‹\n",
        "    if not subject_status.empty:\n",
        "        result = result.merge(subject_status, on='Screening Number', how='left')\n",
        "        print(f\"âœ“ è©¦é©—ç‹€æ…‹å·²æ•´åˆ\")\n",
        "    else:\n",
        "        result['è©¦é©—ç‹€æ…‹'] = None\n",
        "\n",
        "    # è™•ç† missing å€¼ - å°‡SF_or_EOS_dateçš„NaNæ›¿æ›ç‚º'å°šæœªå¡«æ—¥æœŸ'\n",
        "    result['SF_or_EOS_date'] = result['SF_or_EOS_date'].fillna('å°šæœªå¡«æ—¥æœŸ')\n",
        "\n",
        "    # æ’é™¤æŒ‡å®šçš„å—è©¦è€…\n",
        "    before_exclude = len(result)\n",
        "    result = result[~result['Screening Number'].isin(EXCLUDE_SUBJECTS)]\n",
        "    after_exclude = len(result)\n",
        "    if before_exclude > after_exclude:\n",
        "        print(f\"âœ“ å·²æ’é™¤ {before_exclude - after_exclude} ä½å—è©¦è€…ï¼š{', '.join(EXCLUDE_SUBJECTS)}\")\n",
        "\n",
        "    print(f\"âœ“ åˆä½µå®Œæˆï¼š{len(result)} ä½å—è©¦è€…\")\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def calculate_metrics(df):\n",
        "    \"\"\"è¨ˆç®—å„ç¨®æŒ‡æ¨™\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ğŸ“Š æ­¥é©Ÿ 5ï¼šè¨ˆç®—æŒ‡æ¨™\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # å°‡'å°šæœªå¡«æ—¥æœŸ'æ›¿æ›ç‚ºNaTä»¥ä¾¿è¨ˆç®—\n",
        "    df['SF_or_EOS_date_dt'] = df['SF_or_EOS_date'].replace('å°šæœªå¡«æ—¥æœŸ', pd.NaT)\n",
        "    df['SF_or_EOS_date_dt'] = pd.to_datetime(df['SF_or_EOS_date_dt'])\n",
        "\n",
        "    # 1. è¨ˆç®—é—œå¸³å»¶é²å¤©æ•¸\n",
        "    df['days_to_closure'] = np.nan\n",
        "    has_exit = df['SF_or_EOS_date_dt'].notna()\n",
        "    is_expired = df['Status'] == 'Expired'\n",
        "    has_expired_date = df['epro_expired_date'].notna()\n",
        "\n",
        "    valid_closure = has_exit & is_expired & has_expired_date\n",
        "    if valid_closure.any():\n",
        "        df.loc[valid_closure, 'days_to_closure'] = (\n",
        "            pd.to_datetime(df.loc[valid_closure, 'epro_expired_date']) -\n",
        "            df.loc[valid_closure, 'SF_or_EOS_date_dt']\n",
        "        ).dt.days\n",
        "\n",
        "    # 2. é—œå¸³ç‹€æ…‹ï¼ˆå·²ä¸éœ€è¦ï¼Œä½†ä¿ç•™è¨ˆç®—ä»¥é˜²ç¨‹å¼å…¶ä»–åœ°æ–¹ä½¿ç”¨ï¼‰\n",
        "    df['closure_status'] = 'Unknown'\n",
        "    df.loc[has_exit & is_expired, 'closure_status'] = 'Closed'\n",
        "    df.loc[has_exit & (df['Status'] == 'Normal'), 'closure_status'] = 'Not Closed'\n",
        "\n",
        "    # 3. V1åˆ°é–‹å¸³æ—¥æœŸçš„å¤©æ•¸\n",
        "    df['days_V1_to_epro'] = np.nan\n",
        "    has_v1 = df['V1_date'].notna()\n",
        "    has_normal = df['epro_normal_date'].notna()\n",
        "    if (has_v1 & has_normal).any():\n",
        "        df.loc[has_v1 & has_normal, 'days_V1_to_epro'] = (\n",
        "            pd.to_datetime(df.loc[has_v1 & has_normal, 'epro_normal_date']) -\n",
        "            pd.to_datetime(df.loc[has_v1 & has_normal, 'V1_date'])\n",
        "        ).dt.days\n",
        "\n",
        "    # 4. è·é›¢ä»Šå¤©çš„å¤©æ•¸ï¼ˆé‡å°æœ€å¾Œvisitï¼‰\n",
        "    df['days_since_last_visit'] = np.nan\n",
        "    has_last = df['last_visit_date'].notna()\n",
        "    if has_last.any():\n",
        "        df.loc[has_last, 'days_since_last_visit'] = (\n",
        "            TODAY - pd.to_datetime(df.loc[has_last, 'last_visit_date'])\n",
        "        ).dt.days\n",
        "\n",
        "    print(\"âœ“ æŒ‡æ¨™è¨ˆç®—å®Œæˆ\")\n",
        "    print(f\"   - æœ‰SF/EOSæ—¥æœŸï¼š{has_exit.sum()} ä½\")\n",
        "    print(f\"   - å·²é—œå¸³ï¼š{(df['closure_status'] == 'Closed').sum()} ä½\")\n",
        "    print(f\"   - æœªé—œå¸³ï¼š{(df['closure_status'] == 'Not Closed').sum()} ä½\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def identify_issues(df):\n",
        "    \"\"\"è­˜åˆ¥å•é¡Œ\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ğŸ” æ­¥é©Ÿ 6ï¼šè­˜åˆ¥å•é¡Œ\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # å•é¡Œ1ï¼šæœªé—œå¸³æ¸…å–®(æœ‰å¡«EOS/SFé )\n",
        "    print(\"\\nğŸ”´ å•é¡Œ 1ï¼šæœªé—œå¸³æ¸…å–®(æœ‰å¡«EOS/SFé )\")\n",
        "    print(\"-\"*80)\n",
        "    not_closed = df[\n",
        "        (df['SF_or_EOS_date'] != 'å°šæœªå¡«æ—¥æœŸ') &\n",
        "        (df['Status'] == 'Normal')\n",
        "    ].copy()\n",
        "\n",
        "    if len(not_closed) > 0:\n",
        "        print(f\"   âš ï¸  {len(not_closed)} ä½æœªé—œå¸³\")\n",
        "        not_closed['days_since_exit'] = (\n",
        "            TODAY - pd.to_datetime(not_closed['SF_or_EOS_date_dt'])\n",
        "        ).dt.days\n",
        "        print(f\"      æœ€ä¹…ï¼š{not_closed['days_since_exit'].max():.0f} å¤©\")\n",
        "        print(f\"\\n   éœ€ç«‹å³è™•ç†ï¼š\")\n",
        "        for _, row in not_closed.sort_values('SF_or_EOS_date_dt').iterrows():\n",
        "            date_str = row['SF_or_EOS_date'] if row['SF_or_EOS_date'] != 'å°šæœªå¡«æ—¥æœŸ' else 'å°šæœªå¡«æ—¥æœŸ'\n",
        "            print(f\"      Screening Number {row['Screening Number']}: {row['exit_reason']} æ–¼ {date_str} \"\n",
        "                  f\"(å·² {int(row['days_since_exit'])} å¤©)\")\n",
        "    else:\n",
        "        print(f\"   âœ“ å…¨éƒ¨å·²é—œå¸³\")\n",
        "\n",
        "    # å•é¡Œ2ï¼šV9å®Œæˆä½†æœªé—œå¸³ (æ²’å¡«EOSé )\n",
        "    print(\"\\nğŸ”´ å•é¡Œ 2ï¼šV9å®Œæˆä½†æœªé—œå¸³ (æ²’å¡«EOSé )\")\n",
        "    print(\"-\"*80)\n",
        "    v9_not_closed = df[\n",
        "        (df['è©¦é©—ç‹€æ…‹'].str.contains('Ongoing', case=False, na=False)) &\n",
        "        (df['last_visit'].notna()) &\n",
        "        (df['last_visit'].str.contains('V9|EOS', case=False, na=False)) &\n",
        "        (~df['last_visit'].str.contains('V6', case=False, na=False)) &  # æ’é™¤ V6\n",
        "        (df['Status'] == 'Normal')\n",
        "    ].copy()\n",
        "\n",
        "    if len(v9_not_closed) > 0:\n",
        "        print(f\"   âš ï¸  {len(v9_not_closed)} ä½å·²å®ŒæˆV9ä½†æœªé—œå¸³\")\n",
        "        print(f\"\\n   è©³ç´°åˆ—è¡¨ï¼š\")\n",
        "        for _, row in v9_not_closed.iterrows():\n",
        "            print(f\"      Screening Number {row['Screening Number']}: {row['last_visit']} å®Œæˆæ–¼ {row['last_visit_date']}, \"\n",
        "                  f\"è·ä»Š {int(row['days_since_last_visit'])} å¤©\")\n",
        "    else:\n",
        "        print(f\"   âœ“ ç„¡æ­¤å•é¡Œ\")\n",
        "\n",
        "    # å•é¡Œ3ï¼šV1_V2è¶…é30å¤©æœªé—œå¸³è™Ÿ (æ²’å¡«SFé )\n",
        "    print(f\"\\nğŸ”´ å•é¡Œ 3ï¼šV1_V2è¶…é{CUTOFF_DAYS}å¤©æœªé—œå¸³è™Ÿ (æ²’å¡«SFé )\")\n",
        "    print(\"-\"*80)\n",
        "    v1v2_not_closed = df[\n",
        "        (df['last_visit'].notna()) &\n",
        "        (df['last_visit'].str.contains('^V1|^V2', case=False, na=False, regex=True)) &\n",
        "        (df['days_since_last_visit'] > CUTOFF_DAYS) &\n",
        "        (df['SF_or_EOS_date'] == 'å°šæœªå¡«æ—¥æœŸ') &\n",
        "        (df['Status'] == 'Normal')  # åªé¡¯ç¤ºæœªé—œå¸³çš„\n",
        "    ].copy()\n",
        "\n",
        "    if len(v1v2_not_closed) > 0:\n",
        "        print(f\"   âš ï¸  {len(v1v2_not_closed)} ä½åªåˆ°V1/V2è¶…é{CUTOFF_DAYS}å¤©ä¸”æœªé—œePROå¸³è™Ÿ\")\n",
        "        print(f\"\\n   è©³ç´°åˆ—è¡¨ï¼š\")\n",
        "        for _, row in v1v2_not_closed.iterrows():\n",
        "            print(f\"      Screening Number {row['Screening Number']}: {row['last_visit']} æ–¼ {row['last_visit_date']}, \"\n",
        "                  f\"è·ä»Š {int(row['days_since_last_visit'])} å¤©\")\n",
        "    else:\n",
        "        print(f\"   âœ“ ç„¡æ­¤å•é¡Œ\")\n",
        "\n",
        "    return not_closed, v9_not_closed, v1v2_not_closed\n",
        "\n",
        "\n",
        "def auto_adjust_column_width(worksheet, df):\n",
        "    \"\"\"è‡ªå‹•èª¿æ•´æ¬„ä½å¯¬åº¦\"\"\"\n",
        "    for idx, col in enumerate(df.columns):\n",
        "        # è¨ˆç®—æ¬„ä½åç¨±çš„é•·åº¦\n",
        "        column_len = len(str(col))\n",
        "\n",
        "        # è¨ˆç®—è©²æ¬„ä½ä¸­æœ€é•·æ•¸æ“šçš„é•·åº¦\n",
        "        if len(df) > 0:\n",
        "            max_len = df[col].astype(str).str.len().max()\n",
        "            column_len = max(column_len, max_len)\n",
        "\n",
        "        # è¨­å®šå¯¬åº¦ï¼Œæœ€å°8ï¼Œæœ€å¤§50\n",
        "        # ä¸­æ–‡å­—ç¬¦éœ€è¦æ›´å¤šç©ºé–“ï¼Œæ‰€ä»¥ä¹˜ä»¥1.2\n",
        "        adjusted_width = min(max(column_len * 1.2 + 2, 8), 50)\n",
        "\n",
        "        # å–å¾—æ¬„ä½å­—æ¯\n",
        "        col_letter = chr(65 + idx) if idx < 26 else chr(65 + idx // 26 - 1) + chr(65 + idx % 26)\n",
        "        worksheet.column_dimensions[col_letter].width = adjusted_width\n",
        "\n",
        "\n",
        "def export_results(df, not_closed, v9_not_closed, v1v2_not_closed, compliance_df,\n",
        "                  bgtrt_issues, nrs_issues, bgtrt_extra_issues, nrs_extra_issues):\n",
        "    \"\"\"åŒ¯å‡ºçµæœåˆ°å–®ä¸€Excelæª”æ¡ˆçš„å¤šå€‹å·¥ä½œè¡¨\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ğŸ’¾ æ­¥é©Ÿ 7ï¼šåŒ¯å‡ºçµæœ\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # æº–å‚™è¼¸å‡ºæ¬„ä½\n",
        "    output_cols = [\n",
        "        'Screening Number', 'è©¦é©—ç‹€æ…‹', 'exit_reason', 'SF_or_EOS_date', 'Status', 'epro_expired_date',\n",
        "        'days_to_closure', 'V1_date', 'epro_normal_date',\n",
        "        'days_V1_to_epro', 'last_visit', 'last_visit_date', 'days_since_last_visit'\n",
        "    ]\n",
        "\n",
        "    for col in output_cols:\n",
        "        if col not in df.columns:\n",
        "            df[col] = None\n",
        "\n",
        "    # æ ¼å¼åŒ–æ—¥æœŸæ¬„ä½ï¼ˆç¢ºä¿åªé¡¯ç¤ºæ—¥æœŸï¼‰\n",
        "    date_cols = ['epro_expired_date', 'V1_date', 'epro_normal_date', 'last_visit_date']\n",
        "    for col in date_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].apply(lambda x: str(x) if pd.notna(x) else '')\n",
        "\n",
        "    # ç‰¹åˆ¥è™•ç†SF_or_EOS_date - å°‡datetimeæ ¼å¼è½‰ç‚ºæ—¥æœŸå­—ä¸²ï¼Œä¿ç•™'å°šæœªå¡«æ—¥æœŸ'\n",
        "    if 'SF_or_EOS_date_dt' in df.columns:\n",
        "        df['SF_or_EOS_date'] = df.apply(\n",
        "            lambda row: str(row['SF_or_EOS_date_dt'].date())\n",
        "            if pd.notna(row['SF_or_EOS_date_dt']) and row['SF_or_EOS_date'] != 'å°šæœªå¡«æ—¥æœŸ'\n",
        "            else row['SF_or_EOS_date'],\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "    # è™•ç† exit_reason ç©ºå€¼\n",
        "    df['exit_reason'] = df['exit_reason'].fillna('æ²’å¡«SFæˆ–EOSé é¢')\n",
        "    df.loc[df['exit_reason'].isna() | (df['exit_reason'] == ''), 'exit_reason'] = 'æ²’å¡«SFæˆ–EOSé é¢'\n",
        "\n",
        "    # è™•ç† Status æ¬„ä½ - å¦‚æœä¸æ˜¯ Normal æˆ– Expiredï¼Œå°±æ˜¯ \"æ²’æœ‰è¾¦ePRO\"\n",
        "    df['Status'] = df['Status'].apply(\n",
        "        lambda x: x if x in ['Normal', 'Expired'] else 'æ²’æœ‰è¾¦ePRO'\n",
        "    )\n",
        "\n",
        "    # é‡æ–°å‘½åæ¬„ä½ç‚ºä¸­æ–‡\n",
        "    column_names = {\n",
        "        'Screening Number': 'Screening Number',\n",
        "        'è©¦é©—ç‹€æ…‹': 'è©¦é©—ç‹€æ…‹',\n",
        "        'exit_reason': 'çµæŸåŸå› ',\n",
        "        'SF_or_EOS_date': 'SFæˆ–EOSæ—¥æœŸ',\n",
        "        'Status': 'ePROå¸³è™Ÿç‹€æ…‹',\n",
        "        'epro_expired_date': 'ePROé—œé–‰æ—¥æœŸ',\n",
        "        'days_to_closure': 'SF/EOSå¾Œå¹¾å¤©é—œePRO',\n",
        "        'V1_date': 'V1æ—¥æœŸ',\n",
        "        'epro_normal_date': 'ePROé–‹å•Ÿæ—¥æœŸ',\n",
        "        'days_V1_to_epro': 'V1åˆ°é–‹å¸³å¤©æ•¸',\n",
        "        'last_visit': 'æœ€æ–°visit',\n",
        "        'last_visit_date': 'æœ€æ–°visitæ—¥æœŸ',\n",
        "        'days_since_last_visit': 'ä¸Šä¸€æ¬¡visitè·ä»Šå¹¾å¤©'\n",
        "    }\n",
        "\n",
        "    # å‰µå»ºå–®ä¸€Excelæª”æ¡ˆï¼ŒåŒ…å«å¤šå€‹å·¥ä½œè¡¨\n",
        "    import os\n",
        "    output_dir = '/mnt/user-data/outputs' if os.path.exists('/mnt/user-data/outputs') else '.'\n",
        "    output_filename = os.path.join(output_dir, 'ePROåˆ†æçµæœ_å®Œæ•´å ±å‘Š.xlsx')\n",
        "    print(f\"\\nğŸ“„ ç”¢ç”Ÿå–®ä¸€Excelæª”æ¡ˆï¼š{output_filename}\")\n",
        "\n",
        "    with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:\n",
        "        # ç²å–workbookå°è±¡ä»¥ä¾¿å‰µå»ºæ¨£å¼\n",
        "        workbook = writer.book\n",
        "\n",
        "        # å®šç¾©æ¨™é¡Œåˆ—æ¨£å¼\n",
        "        from openpyxl.styles import Font, Alignment, PatternFill, Border, Side\n",
        "\n",
        "        header_font = Font(bold=True, size=11)\n",
        "        header_fill = PatternFill(start_color=\"D9E1F2\", end_color=\"D9E1F2\", fill_type=\"solid\")\n",
        "        header_alignment = Alignment(horizontal=\"center\", vertical=\"center\", wrap_text=True)\n",
        "        thin_border = Border(\n",
        "            left=Side(style='thin'),\n",
        "            right=Side(style='thin'),\n",
        "            top=Side(style='thin'),\n",
        "            bottom=Side(style='thin')\n",
        "        )\n",
        "\n",
        "        # æ•¸æ“šåˆ—æ¨£å¼\n",
        "        data_alignment = Alignment(horizontal=\"left\", vertical=\"center\", wrap_text=True)\n",
        "\n",
        "        # å·¥ä½œè¡¨1ï¼šæœªé—œå¸³æ¸…å–®(æœ‰å¡«EOS/SFé )\n",
        "        sheet_name_1 = '1_æœªé—œå¸³æ¸…å–®(æœ‰å¡«EOSæˆ–SFé )'\n",
        "        if len(not_closed) > 0:\n",
        "            print(f\"   âœ“ å·¥ä½œè¡¨ 1ï¼šæœªé—œå¸³æ¸…å–®(æœ‰å¡«EOS/SFé ) ({len(not_closed)} ä½)\")\n",
        "            nc_cols = ['Screening Number', 'è©¦é©—ç‹€æ…‹', 'exit_reason', 'SF_or_EOS_date', 'Status', 'days_since_exit']\n",
        "            nc_names = {k: column_names.get(k, k) for k in nc_cols}\n",
        "            nc_names['days_since_exit'] = 'SF/EOSå¾Œå·²ç¶“éå¹¾å¤©'\n",
        "            nc_export = not_closed[nc_cols].sort_values('days_since_exit', ascending=False)\n",
        "            nc_export = nc_export.rename(columns=nc_names)\n",
        "            nc_export.to_excel(writer, sheet_name=sheet_name_1, index=False)\n",
        "\n",
        "            # å–å¾—worksheetä¸¦å¥—ç”¨æ¨£å¼\n",
        "            worksheet = writer.sheets[sheet_name_1]\n",
        "\n",
        "            # å¥—ç”¨æ¨™é¡Œåˆ—æ¨£å¼\n",
        "            for col_num, value in enumerate(nc_export.columns.values, 1):\n",
        "                cell = worksheet.cell(row=1, column=col_num)\n",
        "                cell.font = header_font\n",
        "                cell.fill = header_fill\n",
        "                cell.alignment = header_alignment\n",
        "                cell.border = thin_border\n",
        "\n",
        "            # å¥—ç”¨æ•¸æ“šåˆ—æ¨£å¼å’Œé‚Šæ¡†\n",
        "            for row_num in range(2, len(nc_export) + 2):\n",
        "                for col_num in range(1, len(nc_export.columns) + 1):\n",
        "                    cell = worksheet.cell(row=row_num, column=col_num)\n",
        "                    cell.alignment = data_alignment\n",
        "                    cell.border = thin_border\n",
        "\n",
        "            # è‡ªå‹•èª¿æ•´æ¬„ä½å¯¬åº¦\n",
        "            auto_adjust_column_width(worksheet, nc_export)\n",
        "        else:\n",
        "            print(\"   âœ“ å·¥ä½œè¡¨ 1ï¼šæœªé—œå¸³æ¸…å–®(æœ‰å¡«EOS/SFé ) (ç„¡è³‡æ–™)\")\n",
        "            empty_df = pd.DataFrame({'èªªæ˜': ['å…¨éƒ¨å·²é—œå¸³']})\n",
        "            empty_df.to_excel(writer, sheet_name=sheet_name_1, index=False)\n",
        "\n",
        "            worksheet = writer.sheets[sheet_name_1]\n",
        "            cell = worksheet.cell(row=1, column=1)\n",
        "            cell.font = header_font\n",
        "            cell.fill = header_fill\n",
        "            cell.alignment = header_alignment\n",
        "            cell.border = thin_border\n",
        "            worksheet.column_dimensions['A'].width = 20\n",
        "\n",
        "        # å·¥ä½œè¡¨2ï¼šV9å®Œæˆä½†æœªé—œå¸³ (æ²’å¡«EOSé )\n",
        "        sheet_name_2 = '2_V9å®Œæˆä½†æœªé—œå¸³(æ²’å¡«EOSé )'\n",
        "        if len(v9_not_closed) > 0:\n",
        "            print(f\"   âœ“ å·¥ä½œè¡¨ 2ï¼šV9å®Œæˆä½†æœªé—œå¸³ (æ²’å¡«EOSé ) ({len(v9_not_closed)} ä½)\")\n",
        "            v9_cols = ['Screening Number', 'è©¦é©—ç‹€æ…‹', 'last_visit', 'last_visit_date', 'days_since_last_visit', 'Status']\n",
        "            v9_names = {k: column_names.get(k, k) for k in v9_cols}\n",
        "            v9_export = v9_not_closed[v9_cols].sort_values('days_since_last_visit', ascending=False)\n",
        "            v9_export = v9_export.rename(columns=v9_names)\n",
        "            v9_export.to_excel(writer, sheet_name=sheet_name_2, index=False)\n",
        "\n",
        "            worksheet = writer.sheets[sheet_name_2]\n",
        "\n",
        "            # å¥—ç”¨æ¨™é¡Œåˆ—æ¨£å¼\n",
        "            for col_num, value in enumerate(v9_export.columns.values, 1):\n",
        "                cell = worksheet.cell(row=1, column=col_num)\n",
        "                cell.font = header_font\n",
        "                cell.fill = header_fill\n",
        "                cell.alignment = header_alignment\n",
        "                cell.border = thin_border\n",
        "\n",
        "            # å¥—ç”¨æ•¸æ“šåˆ—æ¨£å¼å’Œé‚Šæ¡†\n",
        "            for row_num in range(2, len(v9_export) + 2):\n",
        "                for col_num in range(1, len(v9_export.columns) + 1):\n",
        "                    cell = worksheet.cell(row=row_num, column=col_num)\n",
        "                    cell.alignment = data_alignment\n",
        "                    cell.border = thin_border\n",
        "\n",
        "            auto_adjust_column_width(worksheet, v9_export)\n",
        "        else:\n",
        "            print(\"   âœ“ å·¥ä½œè¡¨ 2ï¼šV9å®Œæˆä½†æœªé—œå¸³ (æ²’å¡«EOSé ) (ç„¡è³‡æ–™)\")\n",
        "            empty_df = pd.DataFrame({'èªªæ˜': ['ç„¡æ­¤å•é¡Œ']})\n",
        "            empty_df.to_excel(writer, sheet_name=sheet_name_2, index=False)\n",
        "\n",
        "            worksheet = writer.sheets[sheet_name_2]\n",
        "            cell = worksheet.cell(row=1, column=1)\n",
        "            cell.font = header_font\n",
        "            cell.fill = header_fill\n",
        "            cell.alignment = header_alignment\n",
        "            cell.border = thin_border\n",
        "            worksheet.column_dimensions['A'].width = 20\n",
        "\n",
        "        # å·¥ä½œè¡¨3ï¼šV1_V2è¶…é30å¤©æœªé—œå¸³è™Ÿ (æ²’å¡«SFé )\n",
        "        sheet_name_3 = '3_V1V2è¶…é30å¤©æœªé—œå¸³è™Ÿ(æ²’å¡«SFé )'\n",
        "        if len(v1v2_not_closed) > 0:\n",
        "            print(f\"   âœ“ å·¥ä½œè¡¨ 3ï¼šV1_V2è¶…é30å¤©æœªé—œå¸³è™Ÿ (æ²’å¡«SFé ) ({len(v1v2_not_closed)} ä½)\")\n",
        "            v1v2_cols = ['Screening Number', 'è©¦é©—ç‹€æ…‹', 'last_visit', 'last_visit_date', 'days_since_last_visit',\n",
        "                         'Status', 'SF_or_EOS_date']\n",
        "            v1v2_names = {k: column_names.get(k, k) for k in v1v2_cols}\n",
        "            v1v2_names['SF_or_EOS_date'] = 'SFæ—¥æœŸ'  # ç‰¹åˆ¥ä¿®æ”¹é€™å€‹å·¥ä½œè¡¨çš„æ¬„ä½åç¨±\n",
        "            v1v2_export = v1v2_not_closed[v1v2_cols].sort_values('days_since_last_visit', ascending=False)\n",
        "            v1v2_export = v1v2_export.rename(columns=v1v2_names)\n",
        "            v1v2_export.to_excel(writer, sheet_name=sheet_name_3, index=False)\n",
        "\n",
        "            worksheet = writer.sheets[sheet_name_3]\n",
        "\n",
        "            # å¥—ç”¨æ¨™é¡Œåˆ—æ¨£å¼\n",
        "            for col_num, value in enumerate(v1v2_export.columns.values, 1):\n",
        "                cell = worksheet.cell(row=1, column=col_num)\n",
        "                cell.font = header_font\n",
        "                cell.fill = header_fill\n",
        "                cell.alignment = header_alignment\n",
        "                cell.border = thin_border\n",
        "\n",
        "            # å¥—ç”¨æ•¸æ“šåˆ—æ¨£å¼å’Œé‚Šæ¡†\n",
        "            for row_num in range(2, len(v1v2_export) + 2):\n",
        "                for col_num in range(1, len(v1v2_export.columns) + 1):\n",
        "                    cell = worksheet.cell(row=row_num, column=col_num)\n",
        "                    cell.alignment = data_alignment\n",
        "                    cell.border = thin_border\n",
        "\n",
        "            auto_adjust_column_width(worksheet, v1v2_export)\n",
        "        else:\n",
        "            print(\"   âœ“ å·¥ä½œè¡¨ 3ï¼šV1_V2è¶…é30å¤©æœªé—œå¸³è™Ÿ (æ²’å¡«SFé ) (ç„¡è³‡æ–™)\")\n",
        "            empty_df = pd.DataFrame({'èªªæ˜': ['ç„¡æ­¤å•é¡Œ']})\n",
        "            empty_df.to_excel(writer, sheet_name=sheet_name_3, index=False)\n",
        "\n",
        "            worksheet = writer.sheets[sheet_name_3]\n",
        "            cell = worksheet.cell(row=1, column=1)\n",
        "            cell.font = header_font\n",
        "            cell.fill = header_fill\n",
        "            cell.alignment = header_alignment\n",
        "            cell.border = thin_border\n",
        "            worksheet.column_dimensions['A'].width = 20\n",
        "\n",
        "        # å·¥ä½œè¡¨4ï¼šå®Œæ•´åˆ†æ\n",
        "        sheet_name_9 = '4_SFæˆ–EOSå¾Œé—œå¸³å»¶é²'\n",
        "        print(f\"   âœ“ å·¥ä½œè¡¨ 4ï¼šSFæˆ–EOSå¾Œé—œå¸³å»¶é²\")\n",
        "\n",
        "        # å¾å®Œæ•´åˆ†æä¸­ç¯©é¸æœ‰ SF/EOS ä¸”å·²é—œå¸³çš„è¨˜éŒ„\n",
        "        closure_analysis = df[\n",
        "            (df['SF_or_EOS_date'] != 'å°šæœªå¡«æ—¥æœŸ') &\n",
        "            (df['Status'] == 'Expired') &\n",
        "            (df['days_to_closure'].notna())\n",
        "        ].copy()\n",
        "\n",
        "        if len(closure_analysis) > 0:\n",
        "            closure_cols = ['Screening Number', 'è©¦é©—ç‹€æ…‹', 'exit_reason', 'SF_or_EOS_date',\n",
        "                          'epro_expired_date', 'days_to_closure']\n",
        "            closure_export = closure_analysis[closure_cols].copy()\n",
        "\n",
        "            # æ¨™è¨˜æ˜¯å¦å»¶é²ï¼ˆä¾‹å¦‚è¶…é7å¤©ï¼‰\n",
        "            closure_export['æ˜¯å¦å»¶é²'] = closure_export['days_to_closure'].apply(\n",
        "                lambda x: 'æ˜¯' if x > DELAY_THRESHOLD else 'å¦'\n",
        "            )\n",
        "\n",
        "            closure_export = closure_export.rename(columns={\n",
        "                'Screening Number': 'Screening Number',\n",
        "                'è©¦é©—ç‹€æ…‹': 'è©¦é©—ç‹€æ…‹',\n",
        "                'exit_reason': 'çµæŸåŸå› ',\n",
        "                'SF_or_EOS_date': 'SFæˆ–EOSæ—¥æœŸ',\n",
        "                'epro_expired_date': 'ePROé—œé–‰æ—¥æœŸ',\n",
        "                'days_to_closure': 'SF/EOSå¾Œå¹¾å¤©é—œePRO'\n",
        "            })\n",
        "\n",
        "            # ä¾å»¶é²å¤©æ•¸æ’åº\n",
        "            closure_export = closure_export.sort_values('SF/EOSå¾Œå¹¾å¤©é—œePRO', ascending=False)\n",
        "\n",
        "            closure_export.to_excel(writer, sheet_name=sheet_name_9, index=False)\n",
        "            worksheet = writer.sheets[sheet_name_9]\n",
        "\n",
        "            # å¥—ç”¨æ¨£å¼\n",
        "            for col_num, value in enumerate(closure_export.columns.values, 1):\n",
        "                cell = worksheet.cell(row=1, column=col_num)\n",
        "                cell.font = header_font\n",
        "                cell.fill = header_fill\n",
        "                cell.alignment = header_alignment\n",
        "                cell.border = thin_border\n",
        "\n",
        "            for row_num in range(2, len(closure_export) + 2):\n",
        "                for col_num in range(1, len(closure_export.columns) + 1):\n",
        "                    cell = worksheet.cell(row=row_num, column=col_num)\n",
        "                    cell.alignment = data_alignment\n",
        "                    cell.border = thin_border\n",
        "\n",
        "            auto_adjust_column_width(worksheet, closure_export)\n",
        "\n",
        "            print(f\"      - å·²é—œå¸³å—è©¦è€…ï¼š{len(closure_export)} ä½\")\n",
        "            print(f\"      - å»¶é²é—œå¸³ï¼ˆ>{DELAY_THRESHOLD}å¤©ï¼‰ï¼š{(closure_export['æ˜¯å¦å»¶é²'] == 'æ˜¯').sum()} ä½\")\n",
        "        else:\n",
        "            empty_df = pd.DataFrame({'èªªæ˜': ['ç„¡å·²é—œå¸³è¨˜éŒ„']})\n",
        "            empty_df.to_excel(writer, sheet_name=sheet_name_9, index=False)\n",
        "\n",
        "            worksheet = writer.sheets[sheet_name_9]\n",
        "            cell = worksheet.cell(row=1, column=1)\n",
        "            cell.font = header_font\n",
        "            cell.fill = header_fill\n",
        "            cell.alignment = header_alignment\n",
        "            cell.border = thin_border\n",
        "            worksheet.column_dimensions['A'].width = 20\n",
        "\n",
        "        # å·¥ä½œè¡¨10ï¼šV1å¾Œå»¶é²é–‹å¸³åˆ†æ\n",
        "        sheet_name_10 = '5_V1å¾Œé–‹å¸³å»¶é²'\n",
        "        print(f\"   âœ“ å·¥ä½œè¡¨ 5ï¼šV1å¾Œé–‹å¸³å»¶é²\")\n",
        "\n",
        "        # å¾å®Œæ•´åˆ†æä¸­ç¯©é¸æœ‰ V1 ä¸”æœ‰é–‹å¸³è¨˜éŒ„çš„\n",
        "        opening_analysis = df[\n",
        "            (df['V1_date'].notna()) &\n",
        "            (df['epro_normal_date'].notna()) &\n",
        "            (df['days_V1_to_epro'].notna())\n",
        "        ].copy()\n",
        "\n",
        "        if len(opening_analysis) > 0:\n",
        "            opening_cols = ['Screening Number', 'è©¦é©—ç‹€æ…‹', 'V1_date', 'epro_normal_date', 'days_V1_to_epro']\n",
        "            opening_export = opening_analysis[opening_cols].copy()\n",
        "\n",
        "            # æ¨™è¨˜æ˜¯å¦å»¶é²ï¼ˆä¾‹å¦‚è¶…é0å¤©ï¼Œå³V1ç•¶å¤©æˆ–ä¹‹å‰æ‡‰è©²é–‹å¸³ï¼‰\n",
        "            opening_export['æ˜¯å¦å»¶é²'] = opening_export['days_V1_to_epro'].apply(\n",
        "                lambda x: 'æ˜¯' if x > 0 else 'å¦'\n",
        "            )\n",
        "\n",
        "            # åˆ¤å®šé–‹å¸³æ™‚é–“é»\n",
        "            opening_export['é–‹å¸³æ™‚é–“é»'] = opening_export['days_V1_to_epro'].apply(\n",
        "                lambda x: 'V1å‰é–‹å¸³' if x < 0 else ('V1ç•¶å¤©é–‹å¸³' if x == 0 else 'V1å¾Œé–‹å¸³')\n",
        "            )\n",
        "\n",
        "            opening_export = opening_export.rename(columns={\n",
        "                'Screening Number': 'Screening Number',\n",
        "                'è©¦é©—ç‹€æ…‹': 'è©¦é©—ç‹€æ…‹',\n",
        "                'V1_date': 'V1æ—¥æœŸ',\n",
        "                'epro_normal_date': 'ePROé–‹å•Ÿæ—¥æœŸ',\n",
        "                'days_V1_to_epro': 'V1åˆ°é–‹å¸³å¤©æ•¸'\n",
        "            })\n",
        "\n",
        "            # ä¾å»¶é²å¤©æ•¸æ’åº\n",
        "            opening_export = opening_export.sort_values('V1åˆ°é–‹å¸³å¤©æ•¸', ascending=False)\n",
        "\n",
        "            opening_export.to_excel(writer, sheet_name=sheet_name_10, index=False)\n",
        "            worksheet = writer.sheets[sheet_name_10]\n",
        "\n",
        "            # å¥—ç”¨æ¨£å¼\n",
        "            for col_num, value in enumerate(opening_export.columns.values, 1):\n",
        "                cell = worksheet.cell(row=1, column=col_num)\n",
        "                cell.font = header_font\n",
        "                cell.fill = header_fill\n",
        "                cell.alignment = header_alignment\n",
        "                cell.border = thin_border\n",
        "\n",
        "            for row_num in range(2, len(opening_export) + 2):\n",
        "                for col_num in range(1, len(opening_export.columns) + 1):\n",
        "                    cell = worksheet.cell(row=row_num, column=col_num)\n",
        "                    cell.alignment = data_alignment\n",
        "                    cell.border = thin_border\n",
        "\n",
        "            auto_adjust_column_width(worksheet, opening_export)\n",
        "\n",
        "            print(f\"      - æœ‰V1å’Œé–‹å¸³è¨˜éŒ„ï¼š{len(opening_export)} ä½\")\n",
        "            print(f\"      - V1å¾Œæ‰é–‹å¸³ï¼š{(opening_export['æ˜¯å¦å»¶é²'] == 'æ˜¯').sum()} ä½\")\n",
        "            print(f\"      - V1ç•¶å¤©é–‹å¸³ï¼š{(opening_export['é–‹å¸³æ™‚é–“é»'] == 'V1ç•¶å¤©é–‹å¸³').sum()} ä½\")\n",
        "            print(f\"      - V1å‰é–‹å¸³ï¼š{(opening_export['é–‹å¸³æ™‚é–“é»'] == 'V1å‰é–‹å¸³').sum()} ä½\")\n",
        "        else:\n",
        "            empty_df = pd.DataFrame({'èªªæ˜': ['ç„¡V1å’Œé–‹å¸³è¨˜éŒ„']})\n",
        "            empty_df.to_excel(writer, sheet_name=sheet_name_10, index=False)\n",
        "\n",
        "            worksheet = writer.sheets[sheet_name_10]\n",
        "            cell = worksheet.cell(row=1, column=1)\n",
        "            cell.font = header_font\n",
        "            cell.fill = header_fill\n",
        "            cell.alignment = header_alignment\n",
        "            cell.border = thin_border\n",
        "            worksheet.column_dimensions['A'].width = 20\n",
        "\n",
        "\n",
        "\n",
        "        sheet_name_4 = '6_ePROå¸³è™Ÿå®Œæ•´åˆ†æ'\n",
        "        print(f\"   âœ“ å·¥ä½œè¡¨ 6ï¼šePROå¸³è™Ÿå®Œæ•´åˆ†æ\")\n",
        "        full = df[output_cols].copy()\n",
        "        full = full.rename(columns=column_names)\n",
        "        full.to_excel(writer, sheet_name=sheet_name_4, index=False)\n",
        "\n",
        "        worksheet = writer.sheets[sheet_name_4]\n",
        "\n",
        "        # å¥—ç”¨æ¨™é¡Œåˆ—æ¨£å¼\n",
        "        for col_num, value in enumerate(full.columns.values, 1):\n",
        "            cell = worksheet.cell(row=1, column=col_num)\n",
        "            cell.font = header_font\n",
        "            cell.fill = header_fill\n",
        "            cell.alignment = header_alignment\n",
        "            cell.border = thin_border\n",
        "\n",
        "        # å¥—ç”¨æ•¸æ“šåˆ—æ¨£å¼å’Œé‚Šæ¡†\n",
        "        for row_num in range(2, len(full) + 2):\n",
        "            for col_num in range(1, len(full.columns) + 1):\n",
        "                cell = worksheet.cell(row=row_num, column=col_num)\n",
        "                cell.alignment = data_alignment\n",
        "                cell.border = thin_border\n",
        "\n",
        "        auto_adjust_column_width(worksheet, full)\n",
        "\n",
        "        # å·¥ä½œè¡¨5ï¼šå•å·å¡«å¯«å®Œæ•´åˆ†æ\n",
        "        sheet_name_6 = '7_BGTRTå•å·ç¼ºæ¼è©³æƒ…'\n",
        "        if len(bgtrt_issues) > 0:\n",
        "            print(f\"   âœ“ å·¥ä½œè¡¨ 7ï¼šBGTRTå•å·ç¼ºæ¼è©³æƒ… ({len(bgtrt_issues)} ä½)\")\n",
        "\n",
        "            bgtrt_detail_cols = ['Screening Number', 'First visit date', 'Last visit', 'Last visit date',\n",
        "                               'Expected end date', 'Expected days', 'BGTRT filled days',\n",
        "                               'BGTRT missing days', 'BGTRT missing dates']\n",
        "            bgtrt_detail = bgtrt_issues[bgtrt_detail_cols].copy()\n",
        "\n",
        "            # å°‡ç¼ºæ¼æ—¥æœŸåˆ—è¡¨è½‰æ›ç‚ºå­—ä¸²ï¼ˆé¡¯ç¤ºå®Œæ•´æ—¥æœŸï¼‰\n",
        "            bgtrt_detail['BGTRT missing dates'] = bgtrt_detail['BGTRT missing dates'].apply(\n",
        "                lambda x: ', '.join([str(d) for d in x]) if x else ''\n",
        "            )\n",
        "\n",
        "            bgtrt_detail = bgtrt_detail.rename(columns={\n",
        "                'Screening Number': 'Screening Number',\n",
        "                'First visit date': 'é¦–æ¬¡è¨ªè¦–æ—¥æœŸ',\n",
        "                'Last visit': 'æœ€å¾Œè¨ªè¦–',\n",
        "                'Last visit date': 'æœ€å¾Œè¨ªè¦–æ—¥æœŸ',\n",
        "                'Expected end date': 'æ‡‰å¡«è‡³æ—¥æœŸ',\n",
        "                'Expected days': 'æ‡‰å¡«å¤©æ•¸',\n",
        "                'BGTRT filled days': 'å·²å¡«å¤©æ•¸',\n",
        "                'BGTRT missing days': 'ç¼ºæ¼å¤©æ•¸',\n",
        "                'BGTRT missing dates': 'å®Œæ•´ç¼ºæ¼æ—¥æœŸ'\n",
        "            })\n",
        "\n",
        "            bgtrt_detail.to_excel(writer, sheet_name=sheet_name_6, index=False)\n",
        "            worksheet = writer.sheets[sheet_name_6]\n",
        "\n",
        "            for col_num, value in enumerate(bgtrt_detail.columns.values, 1):\n",
        "                cell = worksheet.cell(row=1, column=col_num)\n",
        "                cell.font = header_font\n",
        "                cell.fill = header_fill\n",
        "                cell.alignment = header_alignment\n",
        "                cell.border = thin_border\n",
        "\n",
        "            for row_num in range(2, len(bgtrt_detail) + 2):\n",
        "                for col_num in range(1, len(bgtrt_detail.columns) + 1):\n",
        "                    cell = worksheet.cell(row=row_num, column=col_num)\n",
        "                    cell.alignment = data_alignment\n",
        "                    cell.border = thin_border\n",
        "\n",
        "            auto_adjust_column_width(worksheet, bgtrt_detail)\n",
        "        else:\n",
        "            print(\"   âœ“ å·¥ä½œè¡¨ 7ï¼šBGTRTå•å·ç¼ºæ¼è©³æƒ… (ç„¡ç¼ºæ¼)\")\n",
        "            empty_df = pd.DataFrame({'èªªæ˜': ['æ‰€æœ‰å—è©¦è€…BGTRTå•å·çš†å®Œæ•´å¡«å¯«']})\n",
        "            empty_df.to_excel(writer, sheet_name=sheet_name_6, index=False)\n",
        "\n",
        "            worksheet = writer.sheets[sheet_name_6]\n",
        "            cell = worksheet.cell(row=1, column=1)\n",
        "            cell.font = header_font\n",
        "            cell.fill = header_fill\n",
        "            cell.alignment = header_alignment\n",
        "            cell.border = thin_border\n",
        "            worksheet.column_dimensions['A'].width = 40\n",
        "\n",
        "        # å·¥ä½œè¡¨7ï¼šNRSç¼ºæ¼è©³æƒ…\n",
        "        sheet_name_7 = '8_NRSå•å·ç¼ºæ¼è©³æƒ…'\n",
        "        if len(nrs_issues) > 0:\n",
        "            print(f\"   âœ“ å·¥ä½œè¡¨ 8ï¼šNRSå•å·ç¼ºæ¼è©³æƒ… ({len(nrs_issues)} ä½)\")\n",
        "\n",
        "            nrs_detail_cols = ['Screening Number', 'First visit date', 'Last visit', 'Last visit date',\n",
        "                              'Expected end date', 'Expected days', 'NRS filled days',\n",
        "                              'NRS missing days', 'NRS missing dates']\n",
        "            nrs_detail = nrs_issues[nrs_detail_cols].copy()\n",
        "\n",
        "            # å°‡ç¼ºæ¼æ—¥æœŸåˆ—è¡¨è½‰æ›ç‚ºå­—ä¸²ï¼ˆé¡¯ç¤ºå®Œæ•´æ—¥æœŸï¼‰\n",
        "            nrs_detail['NRS missing dates'] = nrs_detail['NRS missing dates'].apply(\n",
        "                lambda x: ', '.join([str(d) for d in x]) if x else ''\n",
        "            )\n",
        "\n",
        "            nrs_detail = nrs_detail.rename(columns={\n",
        "                'Screening Number': 'Screening Number',\n",
        "                'First visit date': 'é¦–æ¬¡è¨ªè¦–æ—¥æœŸ',\n",
        "                'Last visit': 'æœ€å¾Œè¨ªè¦–',\n",
        "                'Last visit date': 'æœ€å¾Œè¨ªè¦–æ—¥æœŸ',\n",
        "                'Expected end date': 'æ‡‰å¡«è‡³æ—¥æœŸ',\n",
        "                'Expected days': 'æ‡‰å¡«å¤©æ•¸',\n",
        "                'NRS filled days': 'å·²å¡«å¤©æ•¸',\n",
        "                'NRS missing days': 'ç¼ºæ¼å¤©æ•¸',\n",
        "                'NRS missing dates': 'å®Œæ•´ç¼ºæ¼æ—¥æœŸ'\n",
        "            })\n",
        "\n",
        "            nrs_detail.to_excel(writer, sheet_name=sheet_name_7, index=False)\n",
        "            worksheet = writer.sheets[sheet_name_7]\n",
        "\n",
        "            for col_num, value in enumerate(nrs_detail.columns.values, 1):\n",
        "                cell = worksheet.cell(row=1, column=col_num)\n",
        "                cell.font = header_font\n",
        "                cell.fill = header_fill\n",
        "                cell.alignment = header_alignment\n",
        "                cell.border = thin_border\n",
        "\n",
        "            for row_num in range(2, len(nrs_detail) + 2):\n",
        "                for col_num in range(1, len(nrs_detail.columns) + 1):\n",
        "                    cell = worksheet.cell(row=row_num, column=col_num)\n",
        "                    cell.alignment = data_alignment\n",
        "                    cell.border = thin_border\n",
        "\n",
        "            auto_adjust_column_width(worksheet, nrs_detail)\n",
        "        else:\n",
        "            print(\"   âœ“ å·¥ä½œè¡¨ 8ï¼šNRSå•å·ç¼ºæ¼è©³æƒ… (ç„¡ç¼ºæ¼)\")\n",
        "            empty_df = pd.DataFrame({'èªªæ˜': ['æ‰€æœ‰å—è©¦è€…NRSå•å·çš†å®Œæ•´å¡«å¯«']})\n",
        "            empty_df.to_excel(writer, sheet_name=sheet_name_7, index=False)\n",
        "\n",
        "            worksheet = writer.sheets[sheet_name_7]\n",
        "            cell = worksheet.cell(row=1, column=1)\n",
        "            cell.font = header_font\n",
        "            cell.fill = header_fill\n",
        "            cell.alignment = header_alignment\n",
        "            cell.border = thin_border\n",
        "            worksheet.column_dimensions['A'].width = 40\n",
        "\n",
        "        # å·¥ä½œè¡¨8ï¼šå•å·å¤šå¡«è©³æƒ…\n",
        "        sheet_name_8 = '9_å•å·å¤šå¡«è©³æƒ…'\n",
        "\n",
        "        # æº–å‚™å¤šå¡«è³‡æ–™ï¼ŒåŠ å…¥æ›´å¤šæ¬„ä½\n",
        "        bgtrt_extra_detail = bgtrt_extra_issues[['Screening Number', 'First visit date', 'Last visit',\n",
        "                                                  'Last visit date', 'Expected end date',\n",
        "                                                  'BGTRT extra days', 'BGTRT extra dates']].copy()\n",
        "        bgtrt_extra_detail['å•å·é¡å‹'] = 'BGTRT'\n",
        "        bgtrt_extra_detail = bgtrt_extra_detail.rename(columns={\n",
        "            'BGTRT extra days': 'å¤šå¡«å¤©æ•¸',\n",
        "            'BGTRT extra dates': 'å¤šå¡«æ—¥æœŸåˆ—è¡¨'\n",
        "        })\n",
        "\n",
        "        nrs_extra_detail = nrs_extra_issues[['Screening Number', 'First visit date', 'Last visit',\n",
        "                                             'Last visit date', 'Expected end date',\n",
        "                                             'NRS extra days', 'NRS extra dates']].copy()\n",
        "        nrs_extra_detail['å•å·é¡å‹'] = 'NRS'\n",
        "        nrs_extra_detail = nrs_extra_detail.rename(columns={\n",
        "            'NRS extra days': 'å¤šå¡«å¤©æ•¸',\n",
        "            'NRS extra dates': 'å¤šå¡«æ—¥æœŸåˆ—è¡¨'\n",
        "        })\n",
        "\n",
        "        extra_issues_combined = pd.concat([bgtrt_extra_detail, nrs_extra_detail], ignore_index=True)\n",
        "\n",
        "        if len(extra_issues_combined) > 0:\n",
        "            print(f\"   âœ“ å·¥ä½œè¡¨ 9ï¼šå•å·å¤šå¡«è©³æƒ… ({len(extra_issues_combined)} ç­†)\")\n",
        "\n",
        "            # å°‡å¤šå¡«æ—¥æœŸåˆ—è¡¨è½‰æ›ç‚ºå­—ä¸²ï¼ˆé¡¯ç¤ºå®Œæ•´æ—¥æœŸï¼‰\n",
        "            extra_issues_combined['å®Œæ•´å¤šå¡«æ—¥æœŸ'] = extra_issues_combined['å¤šå¡«æ—¥æœŸåˆ—è¡¨'].apply(\n",
        "                lambda x: ', '.join([str(d) for d in x]) if isinstance(x, list) else str(x)\n",
        "            )\n",
        "\n",
        "            # é‡æ–°æ•´ç†æ¬„ä½\n",
        "            extra_detail = pd.DataFrame({\n",
        "                'Screening Number': extra_issues_combined['Screening Number'],\n",
        "                'é¦–æ¬¡è¨ªè¦–æ—¥æœŸ': extra_issues_combined['First visit date'],\n",
        "                'æœ€å¾Œè¨ªè¦–': extra_issues_combined['Last visit'],\n",
        "                'æœ€å¾Œè¨ªè¦–æ—¥æœŸ': extra_issues_combined['Last visit date'],\n",
        "                'æ‡‰å¡«è‡³æ—¥æœŸ': extra_issues_combined['Expected end date'],\n",
        "                'å•å·é¡å‹': extra_issues_combined['å•å·é¡å‹'],\n",
        "                'å¤šå¡«å¤©æ•¸': extra_issues_combined['å¤šå¡«å¤©æ•¸'],\n",
        "                'å®Œæ•´å¤šå¡«æ—¥æœŸ': extra_issues_combined['å®Œæ•´å¤šå¡«æ—¥æœŸ']\n",
        "            })\n",
        "\n",
        "            extra_detail.to_excel(writer, sheet_name=sheet_name_8, index=False)\n",
        "            worksheet = writer.sheets[sheet_name_8]\n",
        "\n",
        "            for col_num, value in enumerate(extra_detail.columns.values, 1):\n",
        "                cell = worksheet.cell(row=1, column=col_num)\n",
        "                cell.font = header_font\n",
        "                cell.fill = header_fill\n",
        "                cell.alignment = header_alignment\n",
        "                cell.border = thin_border\n",
        "\n",
        "            for row_num in range(2, len(extra_detail) + 2):\n",
        "                for col_num in range(1, len(extra_detail.columns) + 1):\n",
        "                    cell = worksheet.cell(row=row_num, column=col_num)\n",
        "                    cell.alignment = data_alignment\n",
        "                    cell.border = thin_border\n",
        "\n",
        "            auto_adjust_column_width(worksheet, extra_detail)\n",
        "        else:\n",
        "            print(\"   âœ“ å·¥ä½œè¡¨ 9ï¼šå•å·å¤šå¡«è©³æƒ… (ç„¡å¤šå¡«)\")\n",
        "            empty_df = pd.DataFrame({'èªªæ˜': ['ç„¡å—è©¦è€…æœ‰å•å·å¤šå¡«æƒ…æ³']})\n",
        "            empty_df.to_excel(writer, sheet_name=sheet_name_8, index=False)\n",
        "\n",
        "            worksheet = writer.sheets[sheet_name_8]\n",
        "            cell = worksheet.cell(row=1, column=1)\n",
        "            cell.font = header_font\n",
        "            cell.fill = header_fill\n",
        "            cell.alignment = header_alignment\n",
        "            cell.border = thin_border\n",
        "            worksheet.column_dimensions['A'].width = 40\n",
        "\n",
        "        # å·¥ä½œè¡¨9ï¼šSF/EOSå¾Œå»¶é²é—œé–‰ePROåˆ†æ\n",
        "        sheet_name_5 = '10_å•å·å¡«å¯«å®Œæ•´åˆ†æ'\n",
        "        print(f\"   âœ“ å·¥ä½œè¡¨ 10ï¼šå•å·å¡«å¯«å®Œæ•´åˆ†æ ({len(compliance_df)} ä½)\")\n",
        "\n",
        "        # æº–å‚™è¼¸å‡ºæ¬„ä½ï¼ˆåŠ å…¥æœ€å¾Œè¨ªè¦–æ—¥æœŸï¼‰\n",
        "        quest_cols = ['Screening Number', 'First visit date', 'Last visit', 'Last visit date',\n",
        "                     'Expected end date', 'Expected days',\n",
        "                     'BGTRT filled days', 'BGTRT missing days', 'BGTRT compliance',\n",
        "                     'NRS filled days', 'NRS missing days', 'NRS compliance']\n",
        "\n",
        "        quest_export = compliance_df[quest_cols].copy()\n",
        "        quest_export = quest_export.rename(columns={\n",
        "            'Screening Number': 'Screening Number',\n",
        "            'First visit date': 'é¦–æ¬¡è¨ªè¦–æ—¥æœŸ',\n",
        "            'Last visit': 'æœ€å¾Œè¨ªè¦–',\n",
        "            'Last visit date': 'æœ€å¾Œè¨ªè¦–æ—¥æœŸ',\n",
        "            'Expected end date': 'æ‡‰å¡«è‡³æ—¥æœŸ',\n",
        "            'Expected days': 'æ‡‰å¡«å¤©æ•¸',\n",
        "            'BGTRT filled days': 'BGTRTå·²å¡«å¤©æ•¸',\n",
        "            'BGTRT missing days': 'BGTRTç¼ºæ¼å¤©æ•¸',\n",
        "            'BGTRT compliance': 'BGTRTå®Œæˆç‡',\n",
        "            'NRS filled days': 'NRSå·²å¡«å¤©æ•¸',\n",
        "            'NRS missing days': 'NRSç¼ºæ¼å¤©æ•¸',\n",
        "            'NRS compliance': 'NRSå®Œæˆç‡'\n",
        "        })\n",
        "\n",
        "        quest_export.to_excel(writer, sheet_name=sheet_name_5, index=False)\n",
        "        worksheet = writer.sheets[sheet_name_5]\n",
        "\n",
        "        # å¥—ç”¨æ¨£å¼\n",
        "        for col_num, value in enumerate(quest_export.columns.values, 1):\n",
        "            cell = worksheet.cell(row=1, column=col_num)\n",
        "            cell.font = header_font\n",
        "            cell.fill = header_fill\n",
        "            cell.alignment = header_alignment\n",
        "            cell.border = thin_border\n",
        "\n",
        "        for row_num in range(2, len(quest_export) + 2):\n",
        "            for col_num in range(1, len(quest_export.columns) + 1):\n",
        "                cell = worksheet.cell(row=row_num, column=col_num)\n",
        "                cell.alignment = data_alignment\n",
        "                cell.border = thin_border\n",
        "\n",
        "        auto_adjust_column_width(worksheet, quest_export)\n",
        "\n",
        "    print(f\"\\nâœ… å®Œæˆï¼æ‰€æœ‰çµæœå·²æ•´åˆåˆ°ï¼š{output_filename}\")\n",
        "\n",
        "    # åœ¨ Colab ç’°å¢ƒä¸­è‡ªå‹•ä¸‹è¼‰\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(\"\\nğŸ“¥ é–‹å§‹ä¸‹è¼‰æª”æ¡ˆ...\")\n",
        "        files.download(output_filename)\n",
        "        print(\"âœ“ æª”æ¡ˆä¸‹è¼‰å®Œæˆ\")\n",
        "    except:\n",
        "        print(\"\\nğŸ’¡ æç¤ºï¼šæª”æ¡ˆå·²ç”¢ç”Ÿï¼Œè«‹å¾æª”æ¡ˆåˆ—è¡¨æ‰‹å‹•ä¸‹è¼‰\")\n",
        "\n",
        "        # å·¥ä½œè¡¨6ï¼šBGTRTç¼ºæ¼è©³æƒ…\n",
        "def generate_summary(df, not_closed, v9_not_closed, v1v2_not_closed, compliance_df,\n",
        "                     bgtrt_issues, nrs_issues, bgtrt_extra_issues, nrs_extra_issues):\n",
        "    \"\"\"ç”¢ç”Ÿæ‘˜è¦\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ğŸ“ˆ åˆ†ææ‘˜è¦\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    total = len(df[df['SF_or_EOS_date'] != 'å°šæœªå¡«æ—¥æœŸ'])\n",
        "    print(f\"\\nğŸ“Š åŸºæœ¬çµ±è¨ˆï¼š\")\n",
        "    print(f\"   ç¸½å—è©¦è€…ï¼š{len(df)} ä½\")\n",
        "    print(f\"   å·² SF/EOSï¼š{total} ä½\")\n",
        "\n",
        "    if total > 0:\n",
        "        sf = len(df[df['exit_reason'] == 'SF'])\n",
        "        eos = len(df[df['exit_reason'] == 'EOS'])\n",
        "        print(f\"\\n   çµæŸåŸå› ï¼š\")\n",
        "        print(f\"      SFï¼š{sf} ä½ ({sf/total*100:.1f}%)\")\n",
        "        print(f\"      EOSï¼š{eos} ä½ ({eos/total*100:.1f}%)\")\n",
        "\n",
        "        closed = len(df[(df['SF_or_EOS_date'] != 'å°šæœªå¡«æ—¥æœŸ') & (df['Status'] == 'Expired')])\n",
        "        print(f\"\\n   é—œå¸³ç‹€æ³ï¼š\")\n",
        "        print(f\"      å·²é—œé–‰ï¼š{closed} ä½ ({closed/total*100:.1f}%)\")\n",
        "        print(f\"      æœªé—œé–‰ï¼š{len(not_closed)} ä½ ({len(not_closed)/total*100:.1f}%)\")\n",
        "\n",
        "    print(f\"\\nğŸš¨ éœ€è™•ç†å•é¡Œï¼š\")\n",
        "    print(f\"   æœªé—œå¸³æ¸…å–®(æœ‰å¡«EOS/SFé )ï¼š{len(not_closed)} ä½\")\n",
        "    print(f\"   V9å®Œæˆä½†æœªé—œå¸³ (æ²’å¡«EOSé )ï¼š{len(v9_not_closed)} ä½\")\n",
        "    print(f\"   V1/V2è¶…é30å¤©æœªé—œå¸³è™Ÿ (æ²’å¡«SFé )ï¼š{len(v1v2_not_closed)} ä½\")\n",
        "\n",
        "    print(f\"\\nğŸ“‹ å•å·å¡«å¯«æƒ…æ³ï¼š\")\n",
        "    print(f\"   Background Treatment æœ‰ç¼ºæ¼ï¼š{len(bgtrt_issues)} ä½\")\n",
        "    print(f\"   NRS æœ‰ç¼ºæ¼ï¼š{len(nrs_issues)} ä½\")\n",
        "    print(f\"   Background Treatment æœ‰å¤šå¡«ï¼š{len(bgtrt_extra_issues)} ä½\")\n",
        "    print(f\"   NRS æœ‰å¤šå¡«ï¼š{len(nrs_extra_issues)} ä½\")\n",
        "\n",
        "    # è¨ˆç®—å¹³å‡å®Œæˆç‡\n",
        "    avg_bgtrt = compliance_df['BGTRT filled days'].sum() / compliance_df['Expected days'].sum() * 100 if compliance_df['Expected days'].sum() > 0 else 0\n",
        "    avg_nrs = compliance_df['NRS filled days'].sum() / compliance_df['Expected days'].sum() * 100 if compliance_df['Expected days'].sum() > 0 else 0\n",
        "    print(f\"\\n   å¹³å‡å•å·å®Œæˆç‡ï¼š\")\n",
        "    print(f\"      Background Treatmentï¼š{avg_bgtrt:.1f}%\")\n",
        "    print(f\"      NRSï¼š{avg_nrs:.1f}%\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"ä¸»ç¨‹å¼\"\"\"\n",
        "\n",
        "    # åœ¨ Colab ç’°å¢ƒä¸Šå‚³æª”æ¡ˆ\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ğŸ“¤ è«‹ä¸Šå‚³æª”æ¡ˆ\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"è«‹ä¸Šå‚³ä»¥ä¸‹æª”æ¡ˆï¼š\")\n",
        "        print(\"1. crf_data.xlsxï¼ˆåŒ…å« SFã€DSã€SV å·¥ä½œè¡¨ï¼‰\")\n",
        "        print(\"2. epro_data.xlsxï¼ˆåŒ…å« epro å·¥ä½œè¡¨ï¼‰\")\n",
        "        print(\"3. subject_list.xlsxï¼ˆåŒ…å« Screening No. å’Œ Status æ¬„ä½ï¼‰\")\n",
        "        print(\"4. epro_content_data.xlsxï¼ˆåŒ…å« BGTRT1ã€BGTRT2ã€NRS1ã€NRS2 å·¥ä½œè¡¨ï¼‰\")\n",
        "        print()\n",
        "\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        # æ‰¾å‡ºä¸Šå‚³çš„æª”æ¡ˆ\n",
        "        crf_file = None\n",
        "        epro_file = None\n",
        "        subject_list_file = None\n",
        "        content_file = None\n",
        "\n",
        "        for filename in uploaded.keys():\n",
        "            if 'crf' in filename.lower() and 'content' not in filename.lower():\n",
        "                crf_file = filename\n",
        "                print(f\"âœ“ æ‰¾åˆ° CRF æª”æ¡ˆï¼š{filename}\")\n",
        "            elif 'epro' in filename.lower() and 'content' not in filename.lower():\n",
        "                epro_file = filename\n",
        "                print(f\"âœ“ æ‰¾åˆ° ePRO æª”æ¡ˆï¼š{filename}\")\n",
        "            elif 'subject' in filename.lower() or 'list' in filename.lower():\n",
        "                subject_list_file = filename\n",
        "                print(f\"âœ“ æ‰¾åˆ° Subject List æª”æ¡ˆï¼š{filename}\")\n",
        "            elif 'content' in filename.lower():\n",
        "                content_file = filename\n",
        "                print(f\"âœ“ æ‰¾åˆ° ePRO Content æª”æ¡ˆï¼š{filename}\")\n",
        "\n",
        "        if not crf_file or not epro_file or not content_file:\n",
        "            print(\"\\nâŒ éŒ¯èª¤ï¼šè«‹ç¢ºèªå·²ä¸Šå‚³æ‰€æœ‰å¿…è¦æª”æ¡ˆ\")\n",
        "            return\n",
        "\n",
        "    except ImportError:\n",
        "        # ä¸åœ¨ Colab ç’°å¢ƒï¼Œä½¿ç”¨é è¨­è·¯å¾‘\n",
        "        print(\"\\nâš ï¸ é Colab ç’°å¢ƒï¼Œä½¿ç”¨é è¨­æª”æ¡ˆè·¯å¾‘\")\n",
        "        crf_file = 'crf_data.xlsx'\n",
        "        epro_file = 'epro_data.xlsx'\n",
        "        subject_list_file = 'subject_list.xlsx'\n",
        "        content_file = 'epro_content_data.xlsx'\n",
        "\n",
        "    # è®€å– ePRO å•å·å¡«å¯«å…§å®¹\n",
        "    bgtrt_all, nrs_all, bgtrt_summary, nrs_summary = read_epro_content_data(content_file)\n",
        "\n",
        "    # è®€å– CRF æ•¸æ“šï¼ˆéœ€è¦åœ¨åˆ†æå•å·åˆè¦æ€§ä¹‹å‰è®€å–ï¼‰\n",
        "    sf, ds, sv = read_crf_data(crf_file)\n",
        "\n",
        "    # è®€å– subject_listï¼ˆè©¦é©—ç‹€æ…‹ï¼‰\n",
        "    if subject_list_file:\n",
        "        subject_status, subject_list_full = read_subject_list(subject_list_file)\n",
        "    else:\n",
        "        print(\"\\nâš ï¸ æœªæä¾› Subject List æª”æ¡ˆï¼Œè©¦é©—ç‹€æ…‹å°‡é¡¯ç¤ºç‚ºç©ºç™½\")\n",
        "        subject_status = pd.DataFrame(columns=['Screening Number', 'è©¦é©—ç‹€æ…‹'])\n",
        "        subject_list_full = pd.DataFrame()\n",
        "\n",
        "    # åˆ†æå•å·å¡«å¯«åˆè¦æ€§ï¼ˆéœ€è¦ sf å’Œ sv è³‡æ–™ï¼‰\n",
        "    if not subject_list_full.empty:\n",
        "        compliance_df, bgtrt_issues, nrs_issues, bgtrt_extra_issues, nrs_extra_issues = \\\n",
        "            analyze_questionnaire_compliance(bgtrt_summary, nrs_summary, subject_list_full, sf, sv)\n",
        "    else:\n",
        "        print(\"\\nâš ï¸ ç„¡æ³•åˆ†æå•å·åˆè¦æ€§ï¼ˆç¼ºå°‘ Subject Listï¼‰\")\n",
        "        compliance_df = pd.DataFrame()\n",
        "        bgtrt_issues = pd.DataFrame()\n",
        "        nrs_issues = pd.DataFrame()\n",
        "        bgtrt_extra_issues = pd.DataFrame()\n",
        "        nrs_extra_issues = pd.DataFrame()\n",
        "\n",
        "    # è®€å– ePRO æ•¸æ“š\n",
        "    epro_latest, epro_expired, epro_normal = read_epro_data(epro_file)\n",
        "\n",
        "    if len(sf) == 0 and len(ds) == 0:\n",
        "        print(\"\\nâŒ ç„¡ CRF æ•¸æ“š\")\n",
        "        return\n",
        "\n",
        "    if len(epro_latest) == 0:\n",
        "        print(\"\\nâŒ ç„¡ ePRO æ•¸æ“š\")\n",
        "        return\n",
        "\n",
        "    # åˆä½µå’Œè¨ˆç®—\n",
        "    merged = merge_all_data(sf, ds, sv, epro_latest, epro_expired, epro_normal, subject_status)\n",
        "    result = calculate_metrics(merged)\n",
        "\n",
        "    # è­˜åˆ¥å•é¡Œ\n",
        "    not_closed, v9_not_closed, v1v2_not_closed = identify_issues(result)\n",
        "\n",
        "    # åŒ¯å‡ºçµæœ\n",
        "    export_results(result, not_closed, v9_not_closed, v1v2_not_closed,\n",
        "                  compliance_df, bgtrt_issues, nrs_issues, bgtrt_extra_issues, nrs_extra_issues)\n",
        "\n",
        "    # æ‘˜è¦\n",
        "    generate_summary(result, not_closed, v9_not_closed, v1v2_not_closed,\n",
        "                    compliance_df, bgtrt_issues, nrs_issues, bgtrt_extra_issues, nrs_extra_issues)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"âœ… å®Œæˆï¼\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}