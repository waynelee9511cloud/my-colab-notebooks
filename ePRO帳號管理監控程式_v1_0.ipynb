{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waynelee9511cloud/my-colab-notebooks/blob/dm-work/ePRO%E5%B8%B3%E8%99%9F%E7%AE%A1%E7%90%86%E7%9B%A3%E6%8E%A7%E7%A8%8B%E5%BC%8F_v1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "coZZZIqBBwOK"
      },
      "outputs": [],
      "source": [
        "#@title ç¬¬ä¸€æ­¥: å®‰è£å¿…è¦å¥—ä»¶\n",
        "!pip install pandas openpyxl -q\n",
        "print('âœ… å¥—ä»¶å®‰è£å®Œæˆï¼')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sTVOFfDBwOL",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ç¬¬äºŒæ­¥: åŸ·è¡Œ ePROå¸³è™Ÿç®¡ç†ç›£æ§ç¨‹å¼\n",
        "\n",
        "# åŸ·è¡Œä¸‹æ–¹ç¨‹å¼ç¢¼å¾Œ,ç³»çµ±æœƒè¦æ±‚æ‚¨ä¸Šå‚³æª”æ¡ˆ:\n",
        "# - crf_data.xlsx(éœ€åŒ…å« SFã€DSã€SV å·¥ä½œè¡¨)\n",
        "# - epro_data.xlsx(éœ€åŒ…å« epro å·¥ä½œè¡¨)\n",
        "# - subject_list.xlsx(éœ€åŒ…å« Screening No. å’Œ Status æ¬„ä½)\n",
        "# å®Œæˆå¾Œæœƒè‡ªå‹•ç”¢ç”Ÿä¸¦ä¸‹è¼‰ ePROå¸³è™Ÿåˆ†æçµæœ_å®Œæ•´å ±å‘Š.xlsx\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ==================== è¨­å®š ====================\n",
        "TODAY = pd.Timestamp('2025-11-04')\n",
        "DELAY_THRESHOLD = 7  # å»¶é²é–¾å€¼(å¤©æ•¸)\n",
        "CUTOFF_DAYS = 30  # V1/V2å¾Œè¶…éå¤šå°‘å¤©éœ€è¦æª¢æŸ¥\n",
        "\n",
        "# ==================== æ’é™¤åå–® ====================\n",
        "# å¦‚æœæœ‰éœ€è¦æ’é™¤çš„å—è©¦è€…,è«‹åœ¨ä¸‹æ–¹åˆ—è¡¨ä¸­æ–°å¢ SN(Screening No.)\n",
        "EXCLUDE_SUBJECTS = [\n",
        "    'ST03008',  # èª¤æ“ä½œ,ä¸ç´å…¥åˆ†æ\n",
        "    # å¯åœ¨æ­¤æ–°å¢æ›´å¤šè¦æ’é™¤çš„å—è©¦è€… SN\n",
        "]\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ğŸ¥ è‡¨åºŠè©¦é©— ePRO å¸³è™Ÿç®¡ç†ç›£æ§ç¨‹å¼\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nğŸ“… åˆ†æåŸºæº–æ—¥æœŸ:{TODAY.strftime('%Y-%m-%d')}\")\n",
        "print(f\"âš ï¸  å»¶é²é–¾å€¼:è¶…é {DELAY_THRESHOLD} å¤©\")\n",
        "print(f\"âš ï¸  V1/V2æª¢æŸ¥é–¾å€¼:è¶…é {CUTOFF_DAYS} å¤©\")\n",
        "if EXCLUDE_SUBJECTS:\n",
        "    print(f\"ğŸš« æ’é™¤å—è©¦è€…:{', '.join(EXCLUDE_SUBJECTS)} (SCèª¤æ“ä½œ,ä¸ç´å…¥åˆ†æ)\")\n",
        "print(\"\\né–‹å§‹åŸ·è¡Œ...\\n\")\n",
        "\n",
        "\n",
        "def read_crf_data(crf_file):\n",
        "    \"\"\"è®€å– CRF æ•¸æ“š\"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"ğŸ“ æ­¥é©Ÿ 1:è®€å– CRF æ•¸æ“š\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # è®€å– SF (Screening Failure)\n",
        "    sf = pd.DataFrame()\n",
        "    if 'SF' in pd.ExcelFile(crf_file).sheet_names:\n",
        "        sf = pd.read_excel(crf_file, sheet_name='SF')\n",
        "        if 'SF date' in sf.columns:\n",
        "            sf['SF date'] = pd.to_datetime(sf['SF date'], errors='coerce').dt.date\n",
        "        print(f\"âœ“ SF å·¥ä½œè¡¨:{len(sf)} ç­†\")\n",
        "\n",
        "    # è®€å– DS (Disposition)\n",
        "    ds = pd.DataFrame()\n",
        "    if 'DS' in pd.ExcelFile(crf_file).sheet_names:\n",
        "        ds = pd.read_excel(crf_file, sheet_name='DS')\n",
        "        if 'EOS date' in ds.columns:\n",
        "            ds['EOS date'] = pd.to_datetime(ds['EOS date'], errors='coerce').dt.date\n",
        "        print(f\"âœ“ DS å·¥ä½œè¡¨:{len(ds)} ç­†\")\n",
        "\n",
        "    # è®€å– SV (Study Visits)\n",
        "    sv = pd.DataFrame()\n",
        "    if 'SV' in pd.ExcelFile(crf_file).sheet_names:\n",
        "        sv = pd.read_excel(crf_file, sheet_name='SV')\n",
        "        if 'Visit Date' in sv.columns:\n",
        "            sv['Visit Date'] = pd.to_datetime(sv['Visit Date'], errors='coerce').dt.date\n",
        "        print(f\"âœ“ SV å·¥ä½œè¡¨:{len(sv)} ç­†\")\n",
        "\n",
        "    return sf, ds, sv\n",
        "\n",
        "\n",
        "def read_epro_data(epro_file):\n",
        "    \"\"\"è®€å– ePRO æ•¸æ“š\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ğŸ“ æ­¥é©Ÿ 2:è®€å– ePRO æ•¸æ“š\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    epro = pd.read_excel(epro_file, sheet_name='epro')\n",
        "    print(f\"âœ“ åŸå§‹æ•¸æ“š:{len(epro)} ç­†\")\n",
        "\n",
        "    # æ¸…ç†æ™‚é–“æ ¼å¼\n",
        "    def clean_datetime(dt_str):\n",
        "        if pd.isna(dt_str):\n",
        "            return None\n",
        "        try:\n",
        "            dt_str = str(dt_str).split('(')[0].strip()\n",
        "            dt = pd.to_datetime(dt_str)\n",
        "            return dt.date()  # åªä¿ç•™æ—¥æœŸ\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    epro['epro_date'] = epro['epro_date_time'].apply(clean_datetime)\n",
        "\n",
        "    # æ³¨æ„:åŸå§‹æ•¸æ“šä¸­Statuså¯èƒ½æ‹¼å¯«ç‚º\"Nomal\"\n",
        "    epro['Status'] = epro['Status'].str.strip()\n",
        "    epro.loc[epro['Status'] == 'Nomal', 'Status'] = 'Normal'\n",
        "\n",
        "    # æœ€æ–°ç‹€æ…‹(Normalæˆ–Expired)\n",
        "    epro_latest = epro.sort_values('epro_date_time', ascending=False).groupby('SN').first().reset_index()\n",
        "    print(f\"âœ“ æœ€æ–°ç‹€æ…‹:{len(epro_latest)} ä½å—è©¦è€…\")\n",
        "    print(f\"   - Normal: {len(epro_latest[epro_latest['Status'] == 'Normal'])}\")\n",
        "    print(f\"   - Expired: {len(epro_latest[epro_latest['Status'] == 'Expired'])}\")\n",
        "\n",
        "    # Expired æ—¥æœŸ\n",
        "    epro_expired = epro[epro['Status'] == 'Expired'][['SN', 'epro_date']].copy()\n",
        "    epro_expired = epro_expired.rename(columns={'epro_date': 'epro_expired_date'})\n",
        "    print(f\"âœ“ Expired è¨˜éŒ„:{len(epro_expired)} ç­†\")\n",
        "\n",
        "    # Normal æ—¥æœŸ(é–‹å¸³æ—¥æœŸ) - ä¿®æ­£:å–ç¬¬ä¸€å€‹ Normal ç‹€æ…‹çš„æ—¥æœŸ\n",
        "    epro_normal = epro[epro['Status'] == 'Normal'].sort_values('epro_date_time').groupby('SN').first().reset_index()\n",
        "    epro_normal = epro_normal[['SN', 'epro_date']].copy()\n",
        "    epro_normal = epro_normal.rename(columns={'epro_date': 'epro_normal_date'})\n",
        "    print(f\"âœ“ Normal è¨˜éŒ„(ç¬¬ä¸€æ¬¡é–‹å¸³):{len(epro_normal)} ç­†\")\n",
        "\n",
        "    return epro_latest, epro_expired, epro_normal\n",
        "\n",
        "\n",
        "def process_sv_data(sv):\n",
        "    \"\"\"è™•ç†SVæ•¸æ“š,æå–V1å’Œæœ€å¾Œvisit\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ğŸ“ æ­¥é©Ÿ 3:è™•ç† Visit æ•¸æ“š\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    if sv.empty:\n",
        "        print(\"âš ï¸ æ²’æœ‰SVæ•¸æ“š\")\n",
        "        return pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "    # æå–V1æ—¥æœŸ\n",
        "    v1 = sv[sv['VISIT'].str.contains('V1', case=False, na=False)].copy()\n",
        "    v1 = v1.sort_values('Visit Date').groupby('SN').first().reset_index()\n",
        "    v1 = v1[['SN', 'Visit Date']].rename(columns={'Visit Date': 'V1_date'})\n",
        "    print(f\"âœ“ V1 è¨˜éŒ„:{len(v1)} ä½å—è©¦è€…\")\n",
        "\n",
        "    # æ‰¾å‡ºæ¯å€‹å—è©¦è€…çš„æœ€å¾Œvisit\n",
        "    sv_sorted = sv.sort_values(['SN', 'Visit Date'])\n",
        "    last_visit = sv_sorted.groupby('SN').last().reset_index()\n",
        "    last_visit = last_visit[['SN', 'VISIT', 'Visit Date']].rename(columns={\n",
        "        'VISIT': 'last_visit',\n",
        "        'Visit Date': 'last_visit_date'\n",
        "    })\n",
        "    print(f\"âœ“ æœ€å¾Œ Visit è¨˜éŒ„:{len(last_visit)} ä½å—è©¦è€…\")\n",
        "\n",
        "    return v1, last_visit\n",
        "\n",
        "\n",
        "def read_subject_list(subject_list_file):\n",
        "    \"\"\"è®€å– Subject List(è©¦é©—ç‹€æ…‹)\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ğŸ“ æ­¥é©Ÿ 3.5:è®€å– Subject List(è©¦é©—ç‹€æ…‹)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    try:\n",
        "        subject_list = pd.read_excel(subject_list_file)\n",
        "\n",
        "        # é¸å–éœ€è¦çš„æ¬„ä½\n",
        "        if 'Screening No.' in subject_list.columns and 'Status' in subject_list.columns:\n",
        "            status_data = subject_list[['Screening No.', 'Status']].copy()\n",
        "            status_data = status_data.rename(columns={\n",
        "                'Screening No.': 'SN',\n",
        "                'Status': 'è©¦é©—ç‹€æ…‹'\n",
        "            })\n",
        "            print(f\"âœ“ Subject List:{len(status_data)} ç­†\")\n",
        "            print(f\"   è©¦é©—ç‹€æ…‹åˆ†å¸ƒ:\")\n",
        "            for status, count in status_data['è©¦é©—ç‹€æ…‹'].value_counts().head(5).items():\n",
        "                print(f\"      - {status}: {count}\")\n",
        "            return status_data\n",
        "        else:\n",
        "            print(\"âš ï¸ Subject List ç¼ºå°‘å¿…è¦æ¬„ä½\")\n",
        "            return pd.DataFrame(columns=['SN', 'è©¦é©—ç‹€æ…‹'])\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ ç„¡æ³•è®€å– Subject List:{e}\")\n",
        "        return pd.DataFrame(columns=['SN', 'è©¦é©—ç‹€æ…‹'])\n",
        "\n",
        "\n",
        "def merge_all_data(sf, ds, sv, epro_latest, epro_expired, epro_normal, subject_status):\n",
        "    \"\"\"åˆä½µæ‰€æœ‰æ•¸æ“š\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ğŸ”— æ­¥é©Ÿ 4:åˆä½µæ•¸æ“š\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # è™•ç†SF\n",
        "    sf_data = sf[['SN', 'SF date']].copy() if not sf.empty else pd.DataFrame(columns=['SN', 'SF date'])\n",
        "    sf_data['exit_reason'] = 'SF'\n",
        "    sf_data = sf_data.rename(columns={'SF date': 'SF_or_EOS_date'})\n",
        "\n",
        "    # è™•ç†DS\n",
        "    ds_data = ds[['SN', 'EOS date']].copy() if not ds.empty else pd.DataFrame(columns=['SN', 'EOS date'])\n",
        "    ds_data['exit_reason'] = 'EOS'\n",
        "    ds_data = ds_data.rename(columns={'EOS date': 'SF_or_EOS_date'})\n",
        "\n",
        "    # åˆä½µSFå’ŒDS\n",
        "    crf_combined = pd.concat([sf_data, ds_data], ignore_index=True)\n",
        "    print(f\"âœ“ CRF æ•¸æ“š:{len(crf_combined)} ç­†(SF: {len(sf_data)}, EOS: {len(ds_data)})\")\n",
        "\n",
        "    # è™•ç†SVæ•¸æ“š\n",
        "    v1_data, last_visit_data = process_sv_data(sv)\n",
        "\n",
        "    # åˆä½µæ‰€æœ‰æ•¸æ“š\n",
        "    result = epro_latest[['SN', 'Status', 'epro_date']].copy()\n",
        "    result = result.rename(columns={'epro_date': 'epro_latest_date'})\n",
        "\n",
        "    # åˆä½µCRFæ•¸æ“š\n",
        "    result = result.merge(crf_combined, on='SN', how='left')\n",
        "\n",
        "    # åˆä½µExpiredæ—¥æœŸ\n",
        "    result = result.merge(epro_expired, on='SN', how='left')\n",
        "\n",
        "    # åˆä½µNormalæ—¥æœŸ(é–‹å¸³æ—¥æœŸ)\n",
        "    result = result.merge(epro_normal, on='SN', how='left')\n",
        "\n",
        "    # åˆä½µV1æ•¸æ“š\n",
        "    result = result.merge(v1_data, on='SN', how='left')\n",
        "\n",
        "    # åˆä½µæœ€å¾Œvisitæ•¸æ“š\n",
        "    result = result.merge(last_visit_data, on='SN', how='left')\n",
        "\n",
        "    # åˆä½µè©¦é©—ç‹€æ…‹\n",
        "    if not subject_status.empty:\n",
        "        result = result.merge(subject_status, on='SN', how='left')\n",
        "        print(f\"âœ“ è©¦é©—ç‹€æ…‹å·²æ•´åˆ\")\n",
        "    else:\n",
        "        result['è©¦é©—ç‹€æ…‹'] = None\n",
        "\n",
        "    # è™•ç† missing å€¼ - å°‡SF_or_EOS_dateçš„NaNæ›¿æ›ç‚º'å°šæœªå¡«æ—¥æœŸ'\n",
        "    result['SF_or_EOS_date'] = result['SF_or_EOS_date'].fillna('å°šæœªå¡«æ—¥æœŸ')\n",
        "\n",
        "    # æ’é™¤æŒ‡å®šçš„å—è©¦è€…\n",
        "    before_exclude = len(result)\n",
        "    result = result[~result['SN'].isin(EXCLUDE_SUBJECTS)]\n",
        "    after_exclude = len(result)\n",
        "    if before_exclude > after_exclude:\n",
        "        print(f\"âœ“ å·²æ’é™¤ {before_exclude - after_exclude} ä½å—è©¦è€…:{', '.join(EXCLUDE_SUBJECTS)}\")\n",
        "\n",
        "    print(f\"âœ“ åˆä½µå®Œæˆ:{len(result)} ä½å—è©¦è€…\")\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def calculate_metrics(df):\n",
        "    \"\"\"è¨ˆç®—å„ç¨®æŒ‡æ¨™\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ğŸ“Š æ­¥é©Ÿ 5:è¨ˆç®—æŒ‡æ¨™\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # å°‡'å°šæœªå¡«æ—¥æœŸ'æ›¿æ›ç‚ºNaTä»¥ä¾¿è¨ˆç®—\n",
        "    df['SF_or_EOS_date_dt'] = df['SF_or_EOS_date'].replace('å°šæœªå¡«æ—¥æœŸ', pd.NaT)\n",
        "    df['SF_or_EOS_date_dt'] = pd.to_datetime(df['SF_or_EOS_date_dt'])\n",
        "\n",
        "    # 1. è¨ˆç®—é—œå¸³å»¶é²å¤©æ•¸\n",
        "    df['days_to_closure'] = np.nan\n",
        "    has_exit = df['SF_or_EOS_date_dt'].notna()\n",
        "    is_expired = df['Status'] == 'Expired'\n",
        "    has_expired_date = df['epro_expired_date'].notna()\n",
        "\n",
        "    valid_closure = has_exit & is_expired & has_expired_date\n",
        "    if valid_closure.any():\n",
        "        df.loc[valid_closure, 'days_to_closure'] = (\n",
        "            pd.to_datetime(df.loc[valid_closure, 'epro_expired_date']) -\n",
        "            df.loc[valid_closure, 'SF_or_EOS_date_dt']\n",
        "        ).dt.days\n",
        "\n",
        "    # 2. é—œå¸³ç‹€æ…‹(å·²ä¸éœ€è¦,ä½†ä¿ç•™è¨ˆç®—ä»¥é˜²ç¨‹å¼å…¶ä»–åœ°æ–¹ä½¿ç”¨)\n",
        "    df['closure_status'] = 'Unknown'\n",
        "    df.loc[has_exit & is_expired, 'closure_status'] = 'Closed'\n",
        "    df.loc[has_exit & (df['Status'] == 'Normal'), 'closure_status'] = 'Not Closed'\n",
        "\n",
        "    # 3. V1åˆ°é–‹å¸³æ—¥æœŸçš„å¤©æ•¸\n",
        "    df['days_V1_to_epro'] = np.nan\n",
        "    has_v1 = df['V1_date'].notna()\n",
        "    has_normal = df['epro_normal_date'].notna()\n",
        "    if (has_v1 & has_normal).any():\n",
        "        df.loc[has_v1 & has_normal, 'days_V1_to_epro'] = (\n",
        "            pd.to_datetime(df.loc[has_v1 & has_normal, 'epro_normal_date']) -\n",
        "            pd.to_datetime(df.loc[has_v1 & has_normal, 'V1_date'])\n",
        "        ).dt.days\n",
        "\n",
        "    # 4. è·é›¢ä»Šå¤©çš„å¤©æ•¸(é‡å°æœ€å¾Œvisit)\n",
        "    df['days_since_last_visit'] = np.nan\n",
        "    has_last = df['last_visit_date'].notna()\n",
        "    if has_last.any():\n",
        "        df.loc[has_last, 'days_since_last_visit'] = (\n",
        "            TODAY - pd.to_datetime(df.loc[has_last, 'last_visit_date'])\n",
        "        ).dt.days\n",
        "\n",
        "    print(\"âœ“ æŒ‡æ¨™è¨ˆç®—å®Œæˆ\")\n",
        "    print(f\"   - æœ‰SF/EOSæ—¥æœŸ:{has_exit.sum()} ä½\")\n",
        "    print(f\"   - å·²é—œå¸³:{(df['closure_status'] == 'Closed').sum()} ä½\")\n",
        "    print(f\"   - æœªé—œå¸³:{(df['closure_status'] == 'Not Closed').sum()} ä½\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def identify_issues(df):\n",
        "    \"\"\"è­˜åˆ¥å•é¡Œ\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ğŸ” æ­¥é©Ÿ 6:è­˜åˆ¥å•é¡Œ\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # å•é¡Œ1:æœªé—œå¸³æ¸…å–®(æœ‰å¡«EOS/SFé )\n",
        "    print(\"\\nğŸ”´ å•é¡Œ 1:æœªé—œå¸³æ¸…å–®(æœ‰å¡«EOS/SFé )\")\n",
        "    print(\"-\"*80)\n",
        "    not_closed = df[\n",
        "        (df['SF_or_EOS_date'] != 'å°šæœªå¡«æ—¥æœŸ') &\n",
        "        (df['Status'] == 'Normal')\n",
        "    ].copy()\n",
        "\n",
        "    if len(not_closed) > 0:\n",
        "        print(f\"   âš ï¸  {len(not_closed)} ä½æœªé—œå¸³\")\n",
        "        not_closed['days_since_exit'] = (\n",
        "            TODAY - pd.to_datetime(not_closed['SF_or_EOS_date_dt'])\n",
        "        ).dt.days\n",
        "        print(f\"      æœ€ä¹…:{not_closed['days_since_exit'].max():.0f} å¤©\")\n",
        "        print(f\"\\n   éœ€ç«‹å³è™•ç†:\")\n",
        "        for _, row in not_closed.sort_values('SF_or_EOS_date_dt').iterrows():\n",
        "            date_str = row['SF_or_EOS_date'] if row['SF_or_EOS_date'] != 'å°šæœªå¡«æ—¥æœŸ' else 'å°šæœªå¡«æ—¥æœŸ'\n",
        "            print(f\"      SN {row['SN']}: {row['exit_reason']} æ–¼ {date_str} \"\n",
        "                  f\"(å·² {int(row['days_since_exit'])} å¤©)\")\n",
        "    else:\n",
        "        print(f\"   âœ“ å…¨éƒ¨å·²é—œå¸³\")\n",
        "\n",
        "    # å•é¡Œ2:V9å®Œæˆä½†æœªé—œå¸³ (æ²’å¡«EOSé )\n",
        "    print(\"\\nğŸ”´ å•é¡Œ 2:V9å®Œæˆä½†æœªé—œå¸³ (æ²’å¡«EOSé )\")\n",
        "    print(\"-\"*80)\n",
        "    v9_not_closed = df[\n",
        "        (df['è©¦é©—ç‹€æ…‹'].str.contains('Ongoing', case=False, na=False)) &\n",
        "        (df['last_visit'].notna()) &\n",
        "        (df['last_visit'].str.contains('V9|EOS', case=False, na=False)) &\n",
        "        (~df['last_visit'].str.contains('V6', case=False, na=False)) &  # æ’é™¤ V6\n",
        "        (df['Status'] == 'Normal')\n",
        "    ].copy()\n",
        "\n",
        "    if len(v9_not_closed) > 0:\n",
        "        print(f\"   âš ï¸  {len(v9_not_closed)} ä½å·²å®ŒæˆV9ä½†æœªé—œå¸³\")\n",
        "        print(f\"\\n   è©³ç´°åˆ—è¡¨:\")\n",
        "        for _, row in v9_not_closed.iterrows():\n",
        "            print(f\"      SN {row['SN']}: {row['last_visit']} å®Œæˆæ–¼ {row['last_visit_date']}, \"\n",
        "                  f\"è·ä»Š {int(row['days_since_last_visit'])} å¤©\")\n",
        "    else:\n",
        "        print(f\"   âœ“ ç„¡æ­¤å•é¡Œ\")\n",
        "\n",
        "    # å•é¡Œ3:V1_V2è¶…é30å¤©æœªé—œå¸³è™Ÿ (æ²’å¡«SFé )\n",
        "    print(f\"\\nğŸ”´ å•é¡Œ 3:V1_V2è¶…é{CUTOFF_DAYS}å¤©æœªé—œå¸³è™Ÿ (æ²’å¡«SFé )\")\n",
        "    print(\"-\"*80)\n",
        "    v1v2_not_closed = df[\n",
        "        (df['last_visit'].notna()) &\n",
        "        (df['last_visit'].str.contains('^V1|^V2', case=False, na=False, regex=True)) &\n",
        "        (df['days_since_last_visit'] > CUTOFF_DAYS) &\n",
        "        (df['SF_or_EOS_date'] == 'å°šæœªå¡«æ—¥æœŸ') &\n",
        "        (df['Status'] == 'Normal')  # åªé¡¯ç¤ºæœªé—œå¸³çš„\n",
        "    ].copy()\n",
        "\n",
        "    if len(v1v2_not_closed) > 0:\n",
        "        print(f\"   âš ï¸  {len(v1v2_not_closed)} ä½åªåˆ°V1/V2è¶…é{CUTOFF_DAYS}å¤©ä¸”æœªé—œePROå¸³è™Ÿ\")\n",
        "        print(f\"\\n   è©³ç´°åˆ—è¡¨:\")\n",
        "        for _, row in v1v2_not_closed.iterrows():\n",
        "            print(f\"      SN {row['SN']}: {row['last_visit']} æ–¼ {row['last_visit_date']}, \"\n",
        "                  f\"è·ä»Š {int(row['days_since_last_visit'])} å¤©\")\n",
        "    else:\n",
        "        print(f\"   âœ“ ç„¡æ­¤å•é¡Œ\")\n",
        "\n",
        "    return not_closed, v9_not_closed, v1v2_not_closed\n",
        "\n",
        "\n",
        "def auto_adjust_column_width(worksheet, df):\n",
        "    \"\"\"è‡ªå‹•èª¿æ•´æ¬„ä½å¯¬åº¦\"\"\"\n",
        "    for idx, col in enumerate(df.columns):\n",
        "        # è¨ˆç®—æ¬„ä½åç¨±çš„é•·åº¦\n",
        "        column_len = len(str(col))\n",
        "\n",
        "        # è¨ˆç®—è©²æ¬„ä½ä¸­æœ€é•·æ•¸æ“šçš„é•·åº¦\n",
        "        if len(df) > 0:\n",
        "            max_len = df[col].astype(str).str.len().max()\n",
        "            column_len = max(column_len, max_len)\n",
        "\n",
        "        # è¨­å®šå¯¬åº¦,æœ€å°8,æœ€å¤§50\n",
        "        # ä¸­æ–‡å­—ç¬¦éœ€è¦æ›´å¤šç©ºé–“,æ‰€ä»¥ä¹˜ä»¥1.2\n",
        "        adjusted_width = min(max(column_len * 1.2 + 2, 8), 50)\n",
        "        worksheet.column_dimensions[chr(65 + idx)].width = adjusted_width\n",
        "\n",
        "\n",
        "def export_results(df, not_closed, v9_not_closed, v1v2_not_closed):\n",
        "    \"\"\"åŒ¯å‡ºçµæœåˆ°å–®ä¸€Excelæª”æ¡ˆçš„å¤šå€‹å·¥ä½œè¡¨\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ğŸ’¾ æ­¥é©Ÿ 7:åŒ¯å‡ºçµæœ\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # æº–å‚™è¼¸å‡ºæ¬„ä½\n",
        "    output_cols = [\n",
        "        'SN', 'è©¦é©—ç‹€æ…‹', 'exit_reason', 'SF_or_EOS_date', 'Status', 'epro_expired_date',\n",
        "        'days_to_closure', 'V1_date', 'epro_normal_date',\n",
        "        'days_V1_to_epro', 'last_visit', 'last_visit_date', 'days_since_last_visit'\n",
        "    ]\n",
        "\n",
        "    for col in output_cols:\n",
        "        if col not in df.columns:\n",
        "            df[col] = None\n",
        "\n",
        "    # æ ¼å¼åŒ–æ—¥æœŸæ¬„ä½(ç¢ºä¿åªé¡¯ç¤ºæ—¥æœŸ)\n",
        "    date_cols = ['epro_expired_date', 'V1_date', 'epro_normal_date', 'last_visit_date']\n",
        "    for col in date_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].apply(lambda x: str(x) if pd.notna(x) else '')\n",
        "\n",
        "    # ç‰¹åˆ¥è™•ç†SF_or_EOS_date - å°‡datetimeæ ¼å¼è½‰ç‚ºæ—¥æœŸå­—ä¸²,ä¿ç•™'å°šæœªå¡«æ—¥æœŸ'\n",
        "    if 'SF_or_EOS_date_dt' in df.columns:\n",
        "        df['SF_or_EOS_date'] = df.apply(\n",
        "            lambda row: str(row['SF_or_EOS_date_dt'].date())\n",
        "            if pd.notna(row['SF_or_EOS_date_dt']) and row['SF_or_EOS_date'] != 'å°šæœªå¡«æ—¥æœŸ'\n",
        "            else row['SF_or_EOS_date'],\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "    # è™•ç† exit_reason ç©ºå€¼\n",
        "    df['exit_reason'] = df['exit_reason'].fillna('æ²’å¡«SFæˆ–EOSé é¢')\n",
        "    df.loc[df['exit_reason'].isna() | (df['exit_reason'] == ''), 'exit_reason'] = 'æ²’å¡«SFæˆ–EOSé é¢'\n",
        "\n",
        "    # è™•ç† Status æ¬„ä½ - å¦‚æœä¸æ˜¯ Normal æˆ– Expired,å°±æ˜¯ \"æ²’æœ‰è¾¦ePRO\"\n",
        "    df['Status'] = df['Status'].apply(\n",
        "        lambda x: x if x in ['Normal', 'Expired'] else 'æ²’æœ‰è¾¦ePRO'\n",
        "    )\n",
        "\n",
        "    # é‡æ–°å‘½åæ¬„ä½ç‚ºä¸­æ–‡\n",
        "    column_names = {\n",
        "        'SN': 'SN',\n",
        "        'è©¦é©—ç‹€æ…‹': 'è©¦é©—ç‹€æ…‹',\n",
        "        'exit_reason': 'çµæŸåŸå› ',\n",
        "        'SF_or_EOS_date': 'SFæˆ–EOSæ—¥æœŸ',\n",
        "        'Status': 'ePROå¸³è™Ÿç‹€æ…‹',\n",
        "        'epro_expired_date': 'ePROé—œé–‰æ—¥æœŸ',\n",
        "        'days_to_closure': 'SF/EOSå¾Œå¹¾å¤©é—œePRO',\n",
        "        'V1_date': 'V1æ—¥æœŸ',\n",
        "        'epro_normal_date': 'ePROé–‹å•Ÿæ—¥æœŸ',\n",
        "        'days_V1_to_epro': 'V1åˆ°é–‹å¸³å¤©æ•¸',\n",
        "        'last_visit': 'æœ€æ–°visit',\n",
        "        'last_visit_date': 'æœ€æ–°visitæ—¥æœŸ',\n",
        "        'days_since_last_visit': 'ä¸Šä¸€æ¬¡visitè·ä»Šå¹¾å¤©'\n",
        "    }\n",
        "\n",
        "    # å‰µå»ºå–®ä¸€Excelæª”æ¡ˆ,åŒ…å«å¤šå€‹å·¥ä½œè¡¨\n",
        "    output_filename = 'ePROå¸³è™Ÿåˆ†æçµæœ_å®Œæ•´å ±å‘Š.xlsx'\n",
        "    print(f\"\\nğŸ“„ ç”¢ç”Ÿå–®ä¸€Excelæª”æ¡ˆ:{output_filename}\")\n",
        "\n",
        "    with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:\n",
        "        # ç²å–workbookå°è±¡ä»¥ä¾¿å‰µå»ºæ¨£å¼\n",
        "        workbook = writer.book\n",
        "\n",
        "        # å®šç¾©æ¨™é¡Œåˆ—æ¨£å¼\n",
        "        from openpyxl.styles import Font, Alignment, PatternFill, Border, Side\n",
        "\n",
        "        header_font = Font(bold=True, size=11)\n",
        "        header_fill = PatternFill(start_color=\"D9E1F2\", end_color=\"D9E1F2\", fill_type=\"solid\")\n",
        "        header_alignment = Alignment(horizontal=\"center\", vertical=\"center\", wrap_text=True)\n",
        "        thin_border = Border(\n",
        "            left=Side(style='thin'),\n",
        "            right=Side(style='thin'),\n",
        "            top=Side(style='thin'),\n",
        "            bottom=Side(style='thin')\n",
        "        )\n",
        "\n",
        "        # æ•¸æ“šåˆ—æ¨£å¼\n",
        "        data_alignment = Alignment(horizontal=\"left\", vertical=\"center\")\n",
        "\n",
        "        # å·¥ä½œè¡¨1:æœªé—œå¸³æ¸…å–®(æœ‰å¡«EOS/SFé )\n",
        "        sheet_name_1 = '1_æœªé—œå¸³æ¸…å–®(æœ‰å¡«EOSæˆ–SFé )'\n",
        "        if len(not_closed) > 0:\n",
        "            print(f\"   âœ“ å·¥ä½œè¡¨ 1:æœªé—œå¸³æ¸…å–®(æœ‰å¡«EOS/SFé ) ({len(not_closed)} ä½)\")\n",
        "            nc_cols = ['SN', 'è©¦é©—ç‹€æ…‹', 'exit_reason', 'SF_or_EOS_date', 'Status', 'days_since_exit']\n",
        "            nc_names = {k: column_names.get(k, k) for k in nc_cols}\n",
        "            nc_names['days_since_exit'] = 'SF/EOSå¾Œå·²ç¶“éå¹¾å¤©'\n",
        "            nc_export = not_closed[nc_cols].sort_values('days_since_exit', ascending=False)\n",
        "            nc_export = nc_export.rename(columns=nc_names)\n",
        "            nc_export.to_excel(writer, sheet_name=sheet_name_1, index=False)\n",
        "\n",
        "            # å–å¾—worksheetä¸¦å¥—ç”¨æ¨£å¼\n",
        "            worksheet = writer.sheets[sheet_name_1]\n",
        "\n",
        "            # å¥—ç”¨æ¨™é¡Œåˆ—æ¨£å¼\n",
        "            for col_num, value in enumerate(nc_export.columns.values, 1):\n",
        "                cell = worksheet.cell(row=1, column=col_num)\n",
        "                cell.font = header_font\n",
        "                cell.fill = header_fill\n",
        "                cell.alignment = header_alignment\n",
        "                cell.border = thin_border\n",
        "\n",
        "            # å¥—ç”¨æ•¸æ“šåˆ—æ¨£å¼å’Œé‚Šæ¡†\n",
        "            for row_num in range(2, len(nc_export) + 2):\n",
        "                for col_num in range(1, len(nc_export.columns) + 1):\n",
        "                    cell = worksheet.cell(row=row_num, column=col_num)\n",
        "                    cell.alignment = data_alignment\n",
        "                    cell.border = thin_border\n",
        "\n",
        "            # è‡ªå‹•èª¿æ•´æ¬„ä½å¯¬åº¦\n",
        "            auto_adjust_column_width(worksheet, nc_export)\n",
        "        else:\n",
        "            print(\"   âœ“ å·¥ä½œè¡¨ 1:æœªé—œå¸³æ¸…å–®(æœ‰å¡«EOS/SFé ) (ç„¡è³‡æ–™)\")\n",
        "            empty_df = pd.DataFrame({'èªªæ˜': ['å…¨éƒ¨å·²é—œå¸³']})\n",
        "            empty_df.to_excel(writer, sheet_name=sheet_name_1, index=False)\n",
        "\n",
        "            worksheet = writer.sheets[sheet_name_1]\n",
        "            cell = worksheet.cell(row=1, column=1)\n",
        "            cell.font = header_font\n",
        "            cell.fill = header_fill\n",
        "            cell.alignment = header_alignment\n",
        "            cell.border = thin_border\n",
        "            worksheet.column_dimensions['A'].width = 20\n",
        "\n",
        "        # å·¥ä½œè¡¨2:V9å®Œæˆä½†æœªé—œå¸³ (æ²’å¡«EOSé )\n",
        "        sheet_name_2 = '2_V9å®Œæˆä½†æœªé—œå¸³(æ²’å¡«EOSé )'\n",
        "        if len(v9_not_closed) > 0:\n",
        "            print(f\"   âœ“ å·¥ä½œè¡¨ 2:V9å®Œæˆä½†æœªé—œå¸³ (æ²’å¡«EOSé ) ({len(v9_not_closed)} ä½)\")\n",
        "            v9_cols = ['SN', 'è©¦é©—ç‹€æ…‹', 'last_visit', 'last_visit_date', 'days_since_last_visit', 'Status']\n",
        "            v9_names = {k: column_names.get(k, k) for k in v9_cols}\n",
        "            v9_export = v9_not_closed[v9_cols].sort_values('days_since_last_visit', ascending=False)\n",
        "            v9_export = v9_export.rename(columns=v9_names)\n",
        "            v9_export.to_excel(writer, sheet_name=sheet_name_2, index=False)\n",
        "\n",
        "            worksheet = writer.sheets[sheet_name_2]\n",
        "\n",
        "            # å¥—ç”¨æ¨™é¡Œåˆ—æ¨£å¼\n",
        "            for col_num, value in enumerate(v9_export.columns.values, 1):\n",
        "                cell = worksheet.cell(row=1, column=col_num)\n",
        "                cell.font = header_font\n",
        "                cell.fill = header_fill\n",
        "                cell.alignment = header_alignment\n",
        "                cell.border = thin_border\n",
        "\n",
        "            # å¥—ç”¨æ•¸æ“šåˆ—æ¨£å¼å’Œé‚Šæ¡†\n",
        "            for row_num in range(2, len(v9_export) + 2):\n",
        "                for col_num in range(1, len(v9_export.columns) + 1):\n",
        "                    cell = worksheet.cell(row=row_num, column=col_num)\n",
        "                    cell.alignment = data_alignment\n",
        "                    cell.border = thin_border\n",
        "\n",
        "            auto_adjust_column_width(worksheet, v9_export)\n",
        "        else:\n",
        "            print(\"   âœ“ å·¥ä½œè¡¨ 2:V9å®Œæˆä½†æœªé—œå¸³ (æ²’å¡«EOSé ) (ç„¡è³‡æ–™)\")\n",
        "            empty_df = pd.DataFrame({'èªªæ˜': ['ç„¡æ­¤å•é¡Œ']})\n",
        "            empty_df.to_excel(writer, sheet_name=sheet_name_2, index=False)\n",
        "\n",
        "            worksheet = writer.sheets[sheet_name_2]\n",
        "            cell = worksheet.cell(row=1, column=1)\n",
        "            cell.font = header_font\n",
        "            cell.fill = header_fill\n",
        "            cell.alignment = header_alignment\n",
        "            cell.border = thin_border\n",
        "            worksheet.column_dimensions['A'].width = 20\n",
        "\n",
        "        # å·¥ä½œè¡¨3:V1_V2è¶…é30å¤©æœªé—œå¸³è™Ÿ (æ²’å¡«SFé )\n",
        "        sheet_name_3 = '3_V1V2è¶…é30å¤©æœªé—œå¸³è™Ÿ(æ²’å¡«SFé )'\n",
        "        if len(v1v2_not_closed) > 0:\n",
        "            print(f\"   âœ“ å·¥ä½œè¡¨ 3:V1_V2è¶…é30å¤©æœªé—œå¸³è™Ÿ (æ²’å¡«SFé ) ({len(v1v2_not_closed)} ä½)\")\n",
        "            v1v2_cols = ['SN', 'è©¦é©—ç‹€æ…‹', 'last_visit', 'last_visit_date', 'days_since_last_visit',\n",
        "                         'Status', 'SF_or_EOS_date']\n",
        "            v1v2_names = {k: column_names.get(k, k) for k in v1v2_cols}\n",
        "            v1v2_names['SF_or_EOS_date'] = 'SFæ—¥æœŸ'  # ç‰¹åˆ¥ä¿®æ”¹é€™å€‹å·¥ä½œè¡¨çš„æ¬„ä½åç¨±\n",
        "            v1v2_export = v1v2_not_closed[v1v2_cols].sort_values('days_since_last_visit', ascending=False)\n",
        "            v1v2_export = v1v2_export.rename(columns=v1v2_names)\n",
        "            v1v2_export.to_excel(writer, sheet_name=sheet_name_3, index=False)\n",
        "\n",
        "            worksheet = writer.sheets[sheet_name_3]\n",
        "\n",
        "            # å¥—ç”¨æ¨™é¡Œåˆ—æ¨£å¼\n",
        "            for col_num, value in enumerate(v1v2_export.columns.values, 1):\n",
        "                cell = worksheet.cell(row=1, column=col_num)\n",
        "                cell.font = header_font\n",
        "                cell.fill = header_fill\n",
        "                cell.alignment = header_alignment\n",
        "                cell.border = thin_border\n",
        "\n",
        "            # å¥—ç”¨æ•¸æ“šåˆ—æ¨£å¼å’Œé‚Šæ¡†\n",
        "            for row_num in range(2, len(v1v2_export) + 2):\n",
        "                for col_num in range(1, len(v1v2_export.columns) + 1):\n",
        "                    cell = worksheet.cell(row=row_num, column=col_num)\n",
        "                    cell.alignment = data_alignment\n",
        "                    cell.border = thin_border\n",
        "\n",
        "            auto_adjust_column_width(worksheet, v1v2_export)\n",
        "        else:\n",
        "            print(\"   âœ“ å·¥ä½œè¡¨ 3:V1_V2è¶…é30å¤©æœªé—œå¸³è™Ÿ (æ²’å¡«SFé ) (ç„¡è³‡æ–™)\")\n",
        "            empty_df = pd.DataFrame({'èªªæ˜': ['ç„¡æ­¤å•é¡Œ']})\n",
        "            empty_df.to_excel(writer, sheet_name=sheet_name_3, index=False)\n",
        "\n",
        "            worksheet = writer.sheets[sheet_name_3]\n",
        "            cell = worksheet.cell(row=1, column=1)\n",
        "            cell.font = header_font\n",
        "            cell.fill = header_fill\n",
        "            cell.alignment = header_alignment\n",
        "            cell.border = thin_border\n",
        "            worksheet.column_dimensions['A'].width = 20\n",
        "\n",
        "        # å·¥ä½œè¡¨4:å®Œæ•´åˆ†æ\n",
        "        sheet_name_4 = '4_å®Œæ•´åˆ†æ'\n",
        "        print(f\"   âœ“ å·¥ä½œè¡¨ 4:å®Œæ•´åˆ†æ\")\n",
        "        full = df[output_cols].copy()\n",
        "        full = full.rename(columns=column_names)\n",
        "        full.to_excel(writer, sheet_name=sheet_name_4, index=False)\n",
        "\n",
        "        worksheet = writer.sheets[sheet_name_4]\n",
        "\n",
        "        # å¥—ç”¨æ¨™é¡Œåˆ—æ¨£å¼\n",
        "        for col_num, value in enumerate(full.columns.values, 1):\n",
        "            cell = worksheet.cell(row=1, column=col_num)\n",
        "            cell.font = header_font\n",
        "            cell.fill = header_fill\n",
        "            cell.alignment = header_alignment\n",
        "            cell.border = thin_border\n",
        "\n",
        "        # å¥—ç”¨æ•¸æ“šåˆ—æ¨£å¼å’Œé‚Šæ¡†\n",
        "        for row_num in range(2, len(full) + 2):\n",
        "            for col_num in range(1, len(full.columns) + 1):\n",
        "                cell = worksheet.cell(row=row_num, column=col_num)\n",
        "                cell.alignment = data_alignment\n",
        "                cell.border = thin_border\n",
        "\n",
        "        auto_adjust_column_width(worksheet, full)\n",
        "\n",
        "    print(f\"\\nâœ… å®Œæˆ!æ‰€æœ‰çµæœå·²æ•´åˆåˆ°:{output_filename}\")\n",
        "\n",
        "    # åœ¨ Colab ç’°å¢ƒä¸­è‡ªå‹•ä¸‹è¼‰\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(\"\\nğŸ“¥ é–‹å§‹ä¸‹è¼‰æª”æ¡ˆ...\")\n",
        "        files.download(output_filename)\n",
        "        print(\"âœ“ æª”æ¡ˆä¸‹è¼‰å®Œæˆ\")\n",
        "    except:\n",
        "        print(\"\\nğŸ’¡ æç¤º:æª”æ¡ˆå·²ç”¢ç”Ÿ,è«‹å¾æª”æ¡ˆåˆ—è¡¨æ‰‹å‹•ä¸‹è¼‰\")\n",
        "\n",
        "\n",
        "def generate_summary(df, not_closed, v9_not_closed, v1v2_not_closed):\n",
        "    \"\"\"ç”¢ç”Ÿæ‘˜è¦\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ğŸ“ˆ åˆ†ææ‘˜è¦\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    total = len(df[df['SF_or_EOS_date'] != 'å°šæœªå¡«æ—¥æœŸ'])\n",
        "    print(f\"\\nğŸ“Š åŸºæœ¬çµ±è¨ˆ:\")\n",
        "    print(f\"   ç¸½å—è©¦è€…:{len(df)} ä½\")\n",
        "    print(f\"   å·² SF/EOS:{total} ä½\")\n",
        "\n",
        "    if total > 0:\n",
        "        sf = len(df[df['exit_reason'] == 'SF'])\n",
        "        eos = len(df[df['exit_reason'] == 'EOS'])\n",
        "        print(f\"\\n   çµæŸåŸå› :\")\n",
        "        print(f\"      SF:{sf} ä½ ({sf/total*100:.1f}%)\")\n",
        "        print(f\"      EOS:{eos} ä½ ({eos/total*100:.1f}%)\")\n",
        "\n",
        "        closed = len(df[(df['SF_or_EOS_date'] != 'å°šæœªå¡«æ—¥æœŸ') & (df['Status'] == 'Expired')])\n",
        "        print(f\"\\n   é—œå¸³ç‹€æ³:\")\n",
        "        print(f\"      å·²é—œé–‰:{closed} ä½ ({closed/total*100:.1f}%)\")\n",
        "        print(f\"      æœªé—œé–‰:{len(not_closed)} ä½ ({len(not_closed)/total*100:.1f}%)\")\n",
        "\n",
        "    print(f\"\\nğŸš¨ éœ€è™•ç†å•é¡Œ:\")\n",
        "    print(f\"   æœªé—œå¸³æ¸…å–®(æœ‰å¡«EOS/SFé ):{len(not_closed)} ä½\")\n",
        "    print(f\"   V9å®Œæˆä½†æœªé—œå¸³ (æ²’å¡«EOSé ):{len(v9_not_closed)} ä½\")\n",
        "    print(f\"   V1/V2è¶…é30å¤©æœªé—œå¸³è™Ÿ (æ²’å¡«SFé ):{len(v1v2_not_closed)} ä½\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"ä¸»ç¨‹å¼\"\"\"\n",
        "\n",
        "    # åœ¨ Colab ç’°å¢ƒä¸Šå‚³æª”æ¡ˆ\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ğŸ“¤ è«‹ä¸Šå‚³æª”æ¡ˆ\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"è«‹ä¸Šå‚³ä»¥ä¸‹æª”æ¡ˆ:\")\n",
        "        print(\"1. crf_data.xlsx(åŒ…å« SFã€DSã€SV å·¥ä½œè¡¨)\")\n",
        "        print(\"2. epro_data.xlsx(åŒ…å« epro å·¥ä½œè¡¨)\")\n",
        "        print(\"3. subject_list.xlsx(åŒ…å« Screening No. å’Œ Status æ¬„ä½)\")\n",
        "        print()\n",
        "\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        # æ‰¾å‡ºä¸Šå‚³çš„æª”æ¡ˆ\n",
        "        crf_file = None\n",
        "        epro_file = None\n",
        "        subject_list_file = None\n",
        "\n",
        "        for filename in uploaded.keys():\n",
        "            if 'crf' in filename.lower():\n",
        "                crf_file = filename\n",
        "                print(f\"âœ“ æ‰¾åˆ° CRF æª”æ¡ˆ:{filename}\")\n",
        "            elif 'epro' in filename.lower():\n",
        "                epro_file = filename\n",
        "                print(f\"âœ“ æ‰¾åˆ° ePRO æª”æ¡ˆ:{filename}\")\n",
        "            elif 'subject' in filename.lower() or 'list' in filename.lower():\n",
        "                subject_list_file = filename\n",
        "                print(f\"âœ“ æ‰¾åˆ° Subject List æª”æ¡ˆ:{filename}\")\n",
        "\n",
        "        if not crf_file or not epro_file:\n",
        "            print(\"\\nâŒ éŒ¯èª¤:è«‹ç¢ºèªæª”ååŒ…å« 'crf' å’Œ 'epro'\")\n",
        "            return\n",
        "\n",
        "    except ImportError:\n",
        "        # ä¸åœ¨ Colab ç’°å¢ƒ,ä½¿ç”¨é è¨­è·¯å¾‘\n",
        "        print(\"\\nâš ï¸ é Colab ç’°å¢ƒ,ä½¿ç”¨é è¨­æª”æ¡ˆè·¯å¾‘\")\n",
        "        crf_file = 'crf_data.xlsx'\n",
        "        epro_file = 'epro_data.xlsx'\n",
        "        subject_list_file = 'subject_list.xlsx'\n",
        "\n",
        "    # è®€å–æ•¸æ“š\n",
        "    sf, ds, sv = read_crf_data(crf_file)\n",
        "    epro_latest, epro_expired, epro_normal = read_epro_data(epro_file)\n",
        "\n",
        "    # è®€å– subject_list(è©¦é©—ç‹€æ…‹)\n",
        "    if subject_list_file:\n",
        "        subject_status = read_subject_list(subject_list_file)\n",
        "    else:\n",
        "        print(\"\\nâš ï¸ æœªæä¾› Subject List æª”æ¡ˆ,è©¦é©—ç‹€æ…‹å°‡é¡¯ç¤ºç‚ºç©ºç™½\")\n",
        "        subject_status = pd.DataFrame(columns=['SN', 'è©¦é©—ç‹€æ…‹'])\n",
        "\n",
        "    if len(sf) == 0 and len(ds) == 0:\n",
        "        print(\"\\nâŒ ç„¡ CRF æ•¸æ“š\")\n",
        "        return\n",
        "\n",
        "    if len(epro_latest) == 0:\n",
        "        print(\"\\nâŒ ç„¡ ePRO æ•¸æ“š\")\n",
        "        return\n",
        "\n",
        "    # åˆä½µå’Œè¨ˆç®—\n",
        "    merged = merge_all_data(sf, ds, sv, epro_latest, epro_expired, epro_normal, subject_status)\n",
        "    result = calculate_metrics(merged)\n",
        "\n",
        "    # è­˜åˆ¥å•é¡Œ\n",
        "    not_closed, v9_not_closed, v1v2_not_closed = identify_issues(result)\n",
        "\n",
        "    # åŒ¯å‡ºçµæœ\n",
        "    export_results(result, not_closed, v9_not_closed, v1v2_not_closed)\n",
        "\n",
        "    # æ‘˜è¦\n",
        "    generate_summary(result, not_closed, v9_not_closed, v1v2_not_closed)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"âœ… å®Œæˆ!\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWFn8ySjBwOM"
      },
      "source": [
        "---\n",
        "For Bestat internal use\n",
        "---\n",
        "\n",
        "**ç‰ˆæœ¬**ï¼šv1.0  \n",
        "**æ—¥æœŸ**ï¼š2025-11-04  \n",
        "**Author**ï¼š Wayne Lee"
      ]
    }
  ]
}