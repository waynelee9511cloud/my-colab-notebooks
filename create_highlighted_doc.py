#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”Ÿæˆå¸¶æœ‰èªæ³•é«˜äº®çš„ MedGemma è¨“ç·´æ•™å­¸æ–‡ä»¶
"""

from docx import Document
from docx.shared import Pt, RGBColor, Cm
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml.ns import qn
from pygments import lex
from pygments.lexers import PythonLexer
from pygments.token import Token
import os

def get_token_color(token_type):
    """æ ¹æ“š token é¡å‹è¿”å›å°æ‡‰çš„é¡è‰²"""
    # ä½¿ç”¨é¡ä¼¼ VS Code Dark+ ä¸»é¡Œçš„é¡è‰²æ–¹æ¡ˆ
    color_map = {
        Token.Keyword: RGBColor(197, 134, 192),          # ç´«è‰² - é—œéµå­— (if, for, def, import)
        Token.Keyword.Namespace: RGBColor(197, 134, 192), # ç´«è‰² - import, from
        Token.Name.Builtin: RGBColor(78, 201, 176),      # é’è‰² - å…§å»ºå‡½æ•¸ (print, len, range)
        Token.Name.Function: RGBColor(220, 220, 170),    # æ·ºé»ƒè‰² - å‡½æ•¸å
        Token.Name.Class: RGBColor(78, 201, 176),        # é’è‰² - é¡å
        Token.String: RGBColor(206, 145, 120),           # æ©˜è‰² - å­—ä¸²
        Token.String.Doc: RGBColor(106, 153, 85),        # ç¶ è‰² - æ–‡æª”å­—ä¸²
        Token.Comment: RGBColor(106, 153, 85),           # ç¶ è‰² - è¨»è§£
        Token.Number: RGBColor(181, 206, 168),           # æ·ºç¶ è‰² - æ•¸å­—
        Token.Operator: RGBColor(212, 212, 212),         # æ·ºç°è‰² - é‹ç®—ç¬¦
        Token.Name: RGBColor(156, 220, 254),             # æ·ºè—è‰² - è®Šæ•¸å
        Token.Punctuation: RGBColor(212, 212, 212),      # æ·ºç°è‰² - æ¨™é»ç¬¦è™Ÿ
    }

    # éè¿´æŸ¥æ‰¾æœ€æ¥è¿‘çš„ token é¡å‹
    while token_type not in color_map and token_type.parent:
        token_type = token_type.parent

    return color_map.get(token_type, RGBColor(212, 212, 212))  # é è¨­æ·ºç°è‰²

def add_highlighted_code(doc, code):
    """æ·»åŠ æœ‰èªæ³•é«˜äº®çš„ç¨‹å¼ç¢¼"""
    # å‰µå»ºæ®µè½
    p = doc.add_paragraph()
    p.style = 'Normal'

    # è¨­å®šæ®µè½èƒŒæ™¯è‰²å’Œé‚Šæ¡†ï¼ˆæ¨¡æ“¬ç¨‹å¼ç¢¼å€å¡Šï¼‰
    p.paragraph_format.left_indent = Cm(1)
    p.paragraph_format.right_indent = Cm(1)
    p.paragraph_format.space_before = Pt(6)
    p.paragraph_format.space_after = Pt(6)

    # ä½¿ç”¨ Pygments è§£æç¨‹å¼ç¢¼
    lexer = PythonLexer()
    tokens = lex(code, lexer)

    # ç‚ºæ¯å€‹ token å‰µå»ºä¸åŒé¡è‰²çš„ run
    for token_type, token_value in tokens:
        run = p.add_run(token_value)
        run.font.name = 'Consolas'
        run.font.size = Pt(9)
        run.font.color.rgb = get_token_color(token_type)

    return p

def add_heading_custom(doc, text, level):
    """æ·»åŠ è‡ªè¨‚æ¨™é¡Œ"""
    h = doc.add_heading(text, level=level)
    if level == 1:
        for run in h.runs:
            run.font.color.rgb = RGBColor(0, 51, 102)
    return h

def add_text(doc, text, bullet=False):
    """æ·»åŠ æ–‡å­—"""
    if bullet:
        p = doc.add_paragraph(text, style='List Bullet')
    else:
        p = doc.add_paragraph(text)
    return p

def create_document():
    """å‰µå»ºå®Œæ•´çš„è¨“ç·´æ–‡ä»¶"""
    doc = Document()

    # è¨­å®šé è¨­å­—é«”
    style = doc.styles['Normal']
    style.font.name = 'Calibri'
    style.font.size = Pt(11)

    # ========== å°é¢ ==========
    title = doc.add_heading('MedGemma é†«ç™‚è¡“èªæ ¡æ­£æ¨¡å‹', 0)
    title.alignment = WD_ALIGN_PARAGRAPH.CENTER

    subtitle = doc.add_heading('Python æ©Ÿå™¨å­¸ç¿’å®Œæ•´è¨“ç·´æ•™å­¸æ–‡ä»¶', 0)
    subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER

    for _ in range(3):
        doc.add_paragraph()

    p = doc.add_paragraph('Notebook 20 å€‹ Cells å®Œæ•´è¬›è§£')
    p.alignment = WD_ALIGN_PARAGRAPH.CENTER
    for run in p.runs:
        run.font.size = Pt(18)
        run.bold = True

    doc.add_paragraph()
    p = doc.add_paragraph('å¸¶æœ‰èªæ³•é«˜äº®çš„ç¨‹å¼ç¢¼ç¯„ä¾‹')
    p.alignment = WD_ALIGN_PARAGRAPH.CENTER
    for run in p.runs:
        run.font.size = Pt(14)
        run.font.color.rgb = RGBColor(100, 100, 100)

    doc.add_page_break()

    # ========== ç›®éŒ„ ==========
    doc.add_heading('ç›®éŒ„', 1)
    cells_info = [
        ('Cell 1', 'å®‰è£å¥—ä»¶'),
        ('Cell 2', 'å°å…¥å‡½å¼åº«'),
        ('Cell 3', 'GPU æª¢æŸ¥'),
        ('Cell 4', 'æ›è¼‰ Google Drive'),
        ('Cell 5', 'ä¸Šå‚³æª”æ¡ˆ'),
        ('Cell 6', 'è®€å–å°ç£è—¥ç‰©åç¨±'),
        ('Cell 7', 'è®€å– Excel è³‡æ–™'),
        ('Cell 8', 'æ•´åˆå°ç£è—¥ç‰©åç¨±'),
        ('Cell 9', 'è³‡æ–™å¹³è¡¡'),
        ('Cell 10', 'è¨­å®šè¨“ç·´åƒæ•¸'),
        ('Cell 11', 'æº–å‚™è¨“ç·´è³‡æ–™æ ¼å¼ä¸¦åˆå§‹åŒ–äº¤å‰é©—è­‰'),
        ('Cell 12', 'Fold 1 è¨“ç·´ï¼ˆå®Œæ•´æµç¨‹ï¼‰'),
        ('Cell 13-16', 'Fold 2-5 è¨“ç·´'),
        ('Cell 17', 'çµ±è¨ˆåˆ†æ'),
        ('Cell 18', 'æ··æ·†çŸ©é™£è¦–è¦ºåŒ–'),
        ('Cell 19', 'æ€§èƒ½æŒ‡æ¨™è¦–è¦ºåŒ–'),
        ('Cell 20', 'ç”Ÿæˆè©³ç´°å ±å‘Š'),
    ]

    for cell_num, cell_desc in cells_info:
        add_text(doc, f'{cell_num}: {cell_desc}', bullet=True)

    doc.add_page_break()

    # ========== Cell 1 ==========
    add_heading_custom(doc, 'Cell 1: å®‰è£å¥—ä»¶', 1)

    doc.add_heading('1.1 å®Œæ•´ç¨‹å¼ç¢¼', 2)
    code1 = """# ==================== CELL 1: å®‰è£å¥—ä»¶ ====================
print('ğŸ“¦ é–‹å§‹å®‰è£å¿…è¦å¥—ä»¶...')
!pip install -q transformers datasets accelerate bitsandbytes peft openpyxl scikit-learn matplotlib seaborn
print('âœ… å¥—ä»¶å®‰è£å®Œæˆï¼')"""

    add_highlighted_code(doc, code1)

    doc.add_heading('1.2 ç¨‹å¼ç¢¼è¬›è§£', 2)
    add_text(doc, 'é€™å€‹ Cell å®‰è£æ‰€æœ‰è¨“ç·´æ‰€éœ€çš„ Python å¥—ä»¶ã€‚')
    add_text(doc, '')
    add_text(doc, 'ã€!pip install å‘½ä»¤ã€‘')
    add_text(doc, 'â€¢ ! ç¬¦è™Ÿï¼šåœ¨ Jupyter/Colab ä¸­åŸ·è¡Œ Shell å‘½ä»¤', bullet=True)
    add_text(doc, 'â€¢ pipï¼šPython çš„å¥—ä»¶ç®¡ç†å·¥å…·', bullet=True)
    add_text(doc, 'â€¢ installï¼šå®‰è£æŒ‡ä»¤', bullet=True)
    add_text(doc, 'â€¢ -qï¼šå®‰éœæ¨¡å¼ï¼ˆquietï¼‰ï¼Œæ¸›å°‘è¼¸å‡ºè¨Šæ¯', bullet=True)

    doc.add_heading('1.3 å¥—ä»¶èªªæ˜', 2)
    add_text(doc, '1. transformersï¼šHuggingFace çš„ Transformer æ¨¡å‹åº«')
    add_text(doc, '2. datasetsï¼šè³‡æ–™é›†è™•ç†å·¥å…·')
    add_text(doc, '3. accelerateï¼šåŠ é€Ÿè¨“ç·´çš„å·¥å…·')
    add_text(doc, '4. bitsandbytesï¼šæ¨¡å‹é‡åŒ–å·¥å…·ï¼ˆç¯€çœè¨˜æ†¶é«”ï¼‰')
    add_text(doc, '5. peftï¼šåƒæ•¸é«˜æ•ˆå¾®èª¿å·¥å…·ï¼ˆLoRAï¼‰')
    add_text(doc, '6. openpyxlï¼šExcel æª”æ¡ˆè®€å–å·¥å…·')
    add_text(doc, '7. scikit-learnï¼šæ©Ÿå™¨å­¸ç¿’è©•ä¼°å·¥å…·')
    add_text(doc, '8. matplotlibï¼šè³‡æ–™è¦–è¦ºåŒ–å·¥å…·')
    add_text(doc, '9. seabornï¼šé€²éšè¦–è¦ºåŒ–å·¥å…·')

    doc.add_heading('1.4 é‡è¦æ¦‚å¿µ', 2)
    add_text(doc, 'ã€é‡åŒ–ï¼ˆQuantizationï¼‰ã€‘')
    add_text(doc, 'å°‡æ¨¡å‹åƒæ•¸å¾ 32 ä½å…ƒå£“ç¸®åˆ° 4 ä½å…ƒï¼Œå¯ä»¥ç¯€çœ 8 å€çš„è¨˜æ†¶é«”ã€‚é€™è®“å¤§å‹æ¨¡å‹ï¼ˆå¦‚ 4B åƒæ•¸çš„ MedGemmaï¼‰èƒ½åœ¨æœ‰é™çš„ GPU è¨˜æ†¶é«”ä¸Šè¨“ç·´ã€‚')
    add_text(doc, '')
    add_text(doc, 'ã€æ¯”å–»ã€‘')
    add_text(doc, 'å®‰è£å¥—ä»¶å°±åƒè³¼è²·å·¥å…·ï¼šå¦‚æœè¦ä¿®è»Šï¼Œä½ ä¸æœƒè‡ªå·±æ‰“é€ æ‰³æ‰‹å’Œèºçµ²èµ·å­ï¼Œè€Œæ˜¯ç›´æ¥è²·ç¾æˆçš„å·¥å…·ã€‚Python å¥—ä»¶å°±æ˜¯ç¨‹å¼è¨­è¨ˆçš„ã€Œå·¥å…·ã€ã€‚')

    doc.add_page_break()

    # ========== Cell 2 ==========
    add_heading_custom(doc, 'Cell 2: å°å…¥å‡½å¼åº«', 1)

    doc.add_heading('2.1 å®Œæ•´ç¨‹å¼ç¢¼', 2)
    code2 = """# ==================== CELL 2: å°å…¥å‡½å¼åº« ====================
import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, BitsAndBytesConfig
from datasets import Dataset
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix
from sklearn.model_selection import KFold
from sklearn.utils import resample
from google.colab import files, drive
import os
import json
import numpy as np
import gc
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings('ignore')
print('âœ… æ‰€æœ‰å‡½å¼åº«å°å…¥å®Œæˆï¼')"""

    add_highlighted_code(doc, code2)

    doc.add_heading('2.2 ä¸»è¦å‡½å¼åº«åˆ†é¡', 2)
    add_text(doc, 'â€¢ è³‡æ–™è™•ç†ï¼špandas (pd), numpy (np)', bullet=True)
    add_text(doc, 'â€¢ æ·±åº¦å­¸ç¿’æ¡†æ¶ï¼štorch (PyTorch)', bullet=True)
    add_text(doc, 'â€¢ æ¨¡å‹ç›¸é—œï¼štransformers, peft, datasets', bullet=True)
    add_text(doc, 'â€¢ è©•ä¼°æŒ‡æ¨™ï¼šsklearn.metrics', bullet=True)
    add_text(doc, 'â€¢ äº¤å‰é©—è­‰ï¼šsklearn.model_selection', bullet=True)
    add_text(doc, 'â€¢ è¦–è¦ºåŒ–ï¼šmatplotlib.pyplot (plt), seaborn (sns)', bullet=True)

    doc.add_heading('2.3 é‡è¦æ¦‚å¿µ', 2)
    add_text(doc, 'ã€æ¨¡çµ„åˆ¥åï¼ˆAliasï¼‰ã€‘')
    add_text(doc, 'ä½¿ç”¨ as çµ¦æ¨¡çµ„å–ç°¡çŸ­çš„åˆ¥åï¼Œè®“ç¨‹å¼ç¢¼æ›´ç°¡æ½”ã€‚ä¾‹å¦‚ï¼špd.DataFrame() æ¯” pandas.DataFrame() æ›´çŸ­ï¼Œä¹Ÿæ˜¯æ¥­ç•Œæ…£ä¾‹ã€‚')

    doc.add_page_break()

    # ========== Cell 3 ==========
    add_heading_custom(doc, 'Cell 3: GPU æª¢æŸ¥', 1)

    doc.add_heading('3.1 å®Œæ•´ç¨‹å¼ç¢¼', 2)
    code3 = """# ==================== CELL 3: GPU æª¢æŸ¥ ====================
print('ğŸ” æª¢æŸ¥ GPU ç‹€æ…‹...')
if not torch.cuda.is_available():
    raise RuntimeError('âŒ éŒ¯èª¤ï¼šéœ€è¦ GPU æ‰èƒ½åŸ·è¡Œæ­¤ç¨‹å¼ï¼')

gpu_name = torch.cuda.get_device_name(0)
gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3

print(f'âœ… GPU å·²å°±ç·’ï¼')
print(f'  GPU å‹è™Ÿ: {gpu_name}')
print(f'  GPU è¨˜æ†¶é«”: {gpu_memory:.2f} GB')

# æ¸…ç©º GPU å¿«å–
torch.cuda.empty_cache()
gc.collect()
print('âœ… GPU å¿«å–å·²æ¸…ç©º')"""

    add_highlighted_code(doc, code3)

    doc.add_heading('3.2 ç¨‹å¼ç¢¼è¬›è§£', 2)
    add_text(doc, 'ã€torch.cuda.is_available()ã€‘')
    add_text(doc, 'æª¢æŸ¥ CUDAï¼ˆNVIDIA GPU é‹ç®—å¹³å°ï¼‰æ˜¯å¦å¯ç”¨ã€‚å¦‚æœæ²’æœ‰ GPU æˆ– GPU æœªå•Ÿç”¨ï¼Œè¿”å› Falseã€‚')
    add_text(doc, '')
    add_text(doc, 'ã€if not æ¢ä»¶ã€‘')
    add_text(doc, 'â€¢ notï¼šé‚è¼¯åè½‰', bullet=True)
    add_text(doc, 'â€¢ å¦‚æœ GPU ä¸å¯ç”¨ï¼ˆFalseï¼‰ï¼Œå‰‡åŸ·è¡Œ if å€å¡Š', bullet=True)
    add_text(doc, '')
    add_text(doc, 'ã€f-string æ ¼å¼åŒ–ã€‘')
    add_text(doc, "f'{è®Šæ•¸:.2f}' è¡¨ç¤ºé¡¯ç¤º 2 ä½å°æ•¸ã€‚ä¾‹å¦‚ï¼šf'{3.14159:.2f}' è¼¸å‡º '3.14'")

    doc.add_heading('3.3 é‡è¦æ¦‚å¿µ', 2)
    add_text(doc, 'ã€GPU vs CPUã€‘')
    add_text(doc, 'GPUï¼ˆåœ–å½¢è™•ç†å™¨ï¼‰å°ˆé–€è™•ç†å¹³è¡Œé‹ç®—ï¼Œè¨“ç·´æ·±åº¦å­¸ç¿’æ¨¡å‹çš„é€Ÿåº¦æ¯” CPU å¿« 10-100 å€ã€‚')

    doc.add_page_break()

    # ========== Cell 9: è³‡æ–™å¹³è¡¡ ==========
    add_heading_custom(doc, 'Cell 9: è³‡æ–™å¹³è¡¡', 1)

    doc.add_heading('9.1 ç‚ºä»€éº¼éœ€è¦è³‡æ–™å¹³è¡¡ï¼Ÿ', 2)
    add_text(doc, 'å¦‚æœè¨“ç·´è³‡æ–™ä¸­ã€Œæ­£ç¢ºè¡“èªã€æœ‰ 900 ç­†ï¼Œã€ŒéŒ¯èª¤è¡“èªã€åªæœ‰ 100 ç­†ï¼ˆæ¯”ä¾‹ 9:1ï¼‰ï¼Œæ¨¡å‹æœƒå‚¾å‘é æ¸¬ã€Œéƒ½æ˜¯æ­£ç¢ºçš„ã€ï¼Œå› ç‚ºé€™æ¨£æº–ç¢ºç‡æœ‰ 90%ï¼')
    add_text(doc, '')
    add_text(doc, 'ä½†å¯¦éš›ä¸Šæ¨¡å‹ä¸¦æ²’æœ‰å­¸æœƒè¾¨è­˜éŒ¯èª¤ï¼Œé€™å°±æ˜¯ã€Œè³‡æ–™ä¸å¹³è¡¡ã€å•é¡Œã€‚')

    doc.add_heading('9.2 å®Œæ•´ç¨‹å¼ç¢¼', 2)
    code9 = """# ==================== CELL 9: è³‡æ–™å¹³è¡¡ ====================
TARGET_ERROR_RATIO = 0.40  # ç›®æ¨™éŒ¯èª¤æ¯”ä¾‹ 40%
MAX_TOTAL_SAMPLES = 3500   # è³‡æ–™ä¸Šé™

current_error_count = len(df[df['Correct_Output'] != 'No issues found.'])
current_correct_count = len(df[df['Correct_Output'] == 'No issues found.'])
current_ratio = current_error_count / len(df)

if current_ratio < TARGET_ERROR_RATIO:
    df_correct = df[df['Correct_Output'] == 'No issues found.'].copy()
    df_error = df[df['Correct_Output'] != 'No issues found.'].copy()

    # ä¸Šæ¡æ¨£éŒ¯èª¤è³‡æ–™
    needed_error_count = int(TARGET_ERROR_RATIO * len(df_correct) / (1 - TARGET_ERROR_RATIO))
    df_error_upsampled = resample(df_error, replace=True, n_samples=needed_error_count, random_state=42)

    # åˆä½µä¸¦æ‰“äº‚
    df = pd.concat([df_correct, df_error_upsampled], ignore_index=True)
    df = df.sample(frac=1, random_state=42).reset_index(drop=True)

    print('ğŸ‰ è³‡æ–™å¹³è¡¡å®Œæˆï¼')"""

    add_highlighted_code(doc, code9)

    doc.add_heading('9.3 é‡é»æ¦‚å¿µ', 2)
    add_text(doc, 'ã€ä¸Šæ¡æ¨£ï¼ˆOversamplingï¼‰ã€‘')
    add_text(doc, 'â€¢ replace=Trueï¼šé‡è¤‡æŠ½æ¨£ï¼ŒåŒä¸€ç­†è³‡æ–™å¯ä»¥è¢«æŠ½åˆ°å¤šæ¬¡', bullet=True)
    add_text(doc, 'â€¢ å¾å°‘é‡è³‡æ–™ä¸­ã€Œè¤‡è£½ã€å‡ºæ›´å¤šæ¨£æœ¬', bullet=True)
    add_text(doc, '')
    add_text(doc, 'ã€ä¸‹æ¡æ¨£ï¼ˆUndersamplingï¼‰ã€‘')
    add_text(doc, 'â€¢ replace=Falseï¼šä¸é‡è¤‡æŠ½æ¨£ï¼Œæ¯ç­†è³‡æ–™æœ€å¤šåªæœƒè¢«æŠ½åˆ°ä¸€æ¬¡', bullet=True)
    add_text(doc, 'â€¢ å¾å¤§é‡è³‡æ–™ä¸­éš¨æ©Ÿé¸å–éƒ¨åˆ†æ¨£æœ¬', bullet=True)
    add_text(doc, '')
    add_text(doc, 'ã€random_state=42ã€‘')
    add_text(doc, 'å›ºå®šéš¨æ©Ÿç¨®å­ï¼Œè®“ã€Œéš¨æ©Ÿã€è®Šå¾—å¯é‡ç¾ã€‚æ¯æ¬¡åŸ·è¡Œçµæœéƒ½ä¸€æ¨£ã€‚')

    doc.add_heading('9.4 æ¯”å–»', 2)
    add_text(doc, 'å°±åƒæº–å‚™è€ƒè©¦é¡Œåº«ï¼Œä½ å¸Œæœ›ã€Œç°¡å–®é¡Œï¼šé›£é¡Œ = 6:4ã€ï¼Œé€™æ¨£æ‰èƒ½å¹³è¡¡è¨“ç·´ã€‚å¦‚æœ 99% éƒ½æ˜¯ç°¡å–®é¡Œï¼Œè€ƒè©¦æ™‚é‡åˆ°é›£é¡Œå°±ä¸æœƒåšäº†ã€‚')

    doc.add_page_break()

    # ========== Cell 10: è¨“ç·´åƒæ•¸ ==========
    add_heading_custom(doc, 'Cell 10: è¨­å®šè¨“ç·´åƒæ•¸', 1)

    doc.add_heading('10.1 å®Œæ•´ç¨‹å¼ç¢¼', 2)
    code10 = """# ==================== CELL 10: è¨­å®šè¨“ç·´åƒæ•¸ ====================
BASE_MODEL_ID = 'google/medgemma-4b-it'
LEARNING_RATE = 1e-4      # 0.0001
NUM_EPOCHS = 3
BATCH_SIZE = 2
MAX_LENGTH = 384
GRADIENT_ACCUMULATION_STEPS = 8
N_SPLITS = 5

print(f'âš™ï¸ è¨“ç·´åƒæ•¸è¨­å®š')
print(f'  æ¨¡å‹: {BASE_MODEL_ID}')
print(f'  æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS}')  # 2 Ã— 8 = 16"""

    add_highlighted_code(doc, code10)

    doc.add_heading('10.2 åƒæ•¸èªªæ˜', 2)
    add_text(doc, 'ã€BASE_MODEL_IDã€‘é è¨“ç·´æ¨¡å‹åç¨±ï¼ˆGoogle çš„é†«ç™‚å°ˆç”¨æ¨¡å‹ï¼‰')
    add_text(doc, 'ã€LEARNING_RATEã€‘å­¸ç¿’ç‡ = 0.0001ï¼Œæ§åˆ¶æ¯æ¬¡æ›´æ–°çš„æ­¥ä¼å¤§å°')
    add_text(doc, 'ã€NUM_EPOCHSã€‘è¨“ç·´è¼ªæ•¸ = 3ï¼Œæ‰€æœ‰è³‡æ–™çœ‹ 3 é')
    add_text(doc, 'ã€BATCH_SIZEã€‘æ‰¹æ¬¡å¤§å° = 2ï¼Œä¸€æ¬¡è™•ç† 2 ç­†è³‡æ–™')
    add_text(doc, 'ã€GRADIENT_ACCUMULATION_STEPSã€‘æ¢¯åº¦ç´¯ç© = 8 æ¬¡')
    add_text(doc, 'ã€N_SPLITSã€‘äº¤å‰é©—è­‰æŠ˜æ•¸ = 5')

    doc.add_heading('10.3 é‡è¦æ¦‚å¿µ', 2)
    add_text(doc, 'ã€å­¸ç¿’ç‡ã€‘')
    add_text(doc, 'â€¢ å¤ªå¤§ï¼šå¯èƒ½è·¨éæœ€ä½³é»ï¼Œåœ¨å±±è°·å…©é‚Šè·³ä¾†è·³å»', bullet=True)
    add_text(doc, 'â€¢ å¤ªå°ï¼šè¨“ç·´å¤ªæ…¢ï¼Œå¯èƒ½æ°¸é åˆ°ä¸äº†è°·åº•', bullet=True)
    add_text(doc, 'â€¢ 0.0001 é©åˆå¾®èª¿é è¨“ç·´æ¨¡å‹', bullet=True)
    add_text(doc, '')
    add_text(doc, 'ã€æ¢¯åº¦ç´¯ç©ã€‘')
    add_text(doc, 'â€¢ å¯¦éš› batch size = 2ï¼ˆGPU è¨˜æ†¶é«”é™åˆ¶ï¼‰', bullet=True)
    add_text(doc, 'â€¢ ç´¯ç© 8 æ¬¡å¾Œæ‰æ›´æ–° = æœ‰æ•ˆ batch size = 16', bullet=True)
    add_text(doc, 'â€¢ æ¯”å–»ï¼šä¸€æ¬¡åªèƒ½æ¬ 2 å¡Šç£šï¼Œä½†æ¬ 8 è¶Ÿå†ä¸€èµ·æ¬ä¸Šæ¨“', bullet=True)

    doc.add_page_break()

    # ========== Cell 12: è¨“ç·´æµç¨‹ ==========
    add_heading_custom(doc, 'Cell 12: Fold 1 è¨“ç·´ï¼ˆæ ¸å¿ƒæµç¨‹ï¼‰', 1)

    doc.add_heading('12.1 è¨“ç·´æµç¨‹æ¦‚è¦½', 2)
    add_text(doc, '1. è¼‰å…¥æ¨¡å‹ï¼ˆ4-bit é‡åŒ–ï¼‰')
    add_text(doc, '2. é…ç½® LoRAï¼ˆåªè¨“ç·´ 0.21% åƒæ•¸ï¼‰')
    add_text(doc, '3. Tokenize è³‡æ–™ï¼ˆæ–‡å­—è½‰æ•¸å­—ï¼‰')
    add_text(doc, '4. è¨­å®šè¨“ç·´åƒæ•¸')
    add_text(doc, '5. è¨“ç·´ 3 epochs')
    add_text(doc, '6. è©•ä¼°æ¸¬è©¦é›†')
    add_text(doc, '7. è¨ˆç®—æŒ‡æ¨™')
    add_text(doc, '8. æ¸…ç†è¨˜æ†¶é«”')

    doc.add_heading('12.2 æ¨¡å‹é‡åŒ–é…ç½®', 2)
    code12_1 = """# 4-bit é‡åŒ–é…ç½®
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,                      # ä½¿ç”¨ 4-bit é‡åŒ–
    bnb_4bit_quant_type='nf4',              # NF4 æ ¼å¼
    bnb_4bit_compute_dtype=torch.float16,   # è¨ˆç®—ç”¨ fp16
    bnb_4bit_use_double_quant=True          # é›™é‡é‡åŒ–
)"""

    add_highlighted_code(doc, code12_1)

    add_text(doc, 'ã€é‡åŒ–æ•ˆæœã€‘')
    add_text(doc, 'â€¢ åŸå§‹ï¼š4B åƒæ•¸ Ã— 32 bits = 16 GB', bullet=True)
    add_text(doc, 'â€¢ é‡åŒ–ï¼š4B åƒæ•¸ Ã— 4 bits = 2 GB', bullet=True)
    add_text(doc, 'â€¢ ç¯€çœ 8 å€è¨˜æ†¶é«”ï¼', bullet=True)

    doc.add_heading('12.3 LoRA é…ç½®', 2)
    code12_2 = """# LoRA é…ç½®
lora_config = LoraConfig(
    r=16,                    # ç§©ï¼ˆrankï¼‰
    lora_alpha=32,           # ç¸®æ”¾ä¿‚æ•¸
    lora_dropout=0.1,        # Dropout æ¯”ä¾‹
    target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj'],
    task_type='CAUSAL_LM',
    bias='none'
)

model = get_peft_model(model, lora_config)
# çµæœï¼šåªè¨“ç·´ 0.21% çš„åƒæ•¸ï¼ˆ840 è¬ / 40 å„„ï¼‰"""

    add_highlighted_code(doc, code12_2)

    add_text(doc, 'ã€LoRA æ¯”å–»ã€‘')
    add_text(doc, 'ä¸ç”¨é‡åšæ•´å¥—è¥¿è£ï¼ˆè¨“ç·´ 40 å„„åƒæ•¸ï¼‰ï¼Œåªèª¿æ•´è¢–å­å’Œè…°åœï¼ˆè¨“ç·´ 840 è¬åƒæ•¸ï¼‰å°±èƒ½å®Œç¾åˆèº«ã€‚')

    doc.add_heading('12.4 Tokenization', 2)
    code12_3 = """# Tokenize å‡½æ•¸
def tokenize_function(examples):
    texts = examples['text']
    tokenized = tokenizer(texts, truncation=True, padding='max_length', max_length=384)
    tokenized['labels'] = tokenized['input_ids'].copy()
    return tokenized

# æ‡‰ç”¨åˆ°è³‡æ–™é›†
train_dataset = Dataset.from_dict(train_data).map(tokenize_function, batched=True)"""

    add_highlighted_code(doc, code12_3)

    add_text(doc, 'ã€Tokenizerã€‘')
    add_text(doc, 'å°‡æ–‡å­—è½‰æˆæ•¸å­—ï¼Œé›»è…¦æ‰èƒ½è™•ç†ã€‚ä¾‹å¦‚ï¼š"diabetes" â†’ [1234, 5678]')

    doc.add_page_break()

    # ========== Cell 17: çµ±è¨ˆåˆ†æ ==========
    add_heading_custom(doc, 'Cell 17: çµ±è¨ˆåˆ†æ', 1)

    doc.add_heading('17.1 è¨ˆç®—å¹³å‡å€¼å’Œæ¨™æº–å·®', 2)
    code17 = """# 5 å€‹ fold çš„ F1 score
values = [0.85, 0.87, 0.83, 0.86, 0.84]

# è¨ˆç®—çµ±è¨ˆé‡
mean = np.mean(values)              # å¹³å‡å€¼: 0.85
std = np.std(values, ddof=1)        # æ¨™æº–å·®: 0.0158

# è¨ˆç®— 95% ä¿¡è³´å€é–“
confidence_level = 0.95
degrees_freedom = len(values) - 1   # è‡ªç”±åº¦ = 4
confidence_interval = stats.t.interval(
    confidence_level,
    degrees_freedom,
    mean,
    stats.sem(values)
)
# çµæœ: [0.8304, 0.8696]"""

    add_highlighted_code(doc, code17)

    doc.add_heading('17.2 é‡è¦æ¦‚å¿µ', 2)
    add_text(doc, 'ã€å¹³å‡å€¼ï¼ˆMeanï¼‰ã€‘')
    add_text(doc, 'ä¸­å¿ƒè¶¨å‹¢ï¼Œ5 æ¬¡æ¸¬è©¦çš„å¹³å‡è¡¨ç¾ã€‚è¨ˆç®—æ–¹å¼ï¼šsum(values) / len(values)')
    add_text(doc, '')
    add_text(doc, 'ã€æ¨™æº–å·®ï¼ˆStandard Deviationï¼‰ã€‘')
    add_text(doc, 'é›¢æ•£ç¨‹åº¦ï¼Œæ•¸å€¼è¶Šå°è¡¨ç¤ºçµæœè¶Šç©©å®šã€‚å…¬å¼ï¼šsqrt(Î£(x - mean)Â² / (n - 1))')
    add_text(doc, '')
    add_text(doc, 'ã€ä¿¡è³´å€é–“ï¼ˆConfidence Intervalï¼‰ã€‘')
    add_text(doc, 'çœŸå¯¦å¹³å‡å€¼æœ‰ 95% æ©Ÿç‡è½åœ¨æ­¤ç¯„åœã€‚å¦‚æœé‡è¤‡å¯¦é©— 100 æ¬¡ï¼Œç´„æœ‰ 95 æ¬¡çš„çµæœæœƒè½åœ¨é€™å€‹å€é–“å…§ã€‚')
    add_text(doc, '')
    add_text(doc, 'ã€ddof=1ã€‘')
    add_text(doc, 'è‡ªç”±åº¦ä¿®æ­£ã€‚å› ç‚ºæˆ‘å€‘åªæœ‰ 5 å€‹æ¨£æœ¬ï¼ˆä¸æ˜¯å…¨éƒ¨è³‡æ–™ï¼‰ï¼Œæ‰€ä»¥ç”¨æ¨£æœ¬æ¨™æº–å·®ï¼ˆddof=1ï¼‰è€Œä¸æ˜¯æ¯é«”æ¨™æº–å·®ï¼ˆddof=0ï¼‰ã€‚')

    doc.add_heading('17.3 æ¯”å–»', 2)
    add_text(doc, 'å°„ç®­ 5 æ¬¡ï¼Œå¹³å‡ 85 åˆ†ã€‚ä¿¡è³´å€é–“å‘Šè¨´ä½ ï¼šå¦‚æœå†å°„ 1000 ç®­ï¼Œ95% çš„æ©Ÿæœƒå¹³å‡åˆ†æ•¸åœ¨ 83-87 åˆ†ä¹‹é–“ã€‚')

    doc.add_page_break()

    # ========== Cell 18: è¦–è¦ºåŒ– ==========
    add_heading_custom(doc, 'Cell 18: æ··æ·†çŸ©é™£è¦–è¦ºåŒ–', 1)

    doc.add_heading('18.1 ä»€éº¼æ˜¯æ··æ·†çŸ©é™£ï¼Ÿ', 2)
    add_text(doc, 'æ··æ·†çŸ©é™£é¡¯ç¤ºæ¨¡å‹é æ¸¬çš„å°éŒ¯æƒ…æ³ï¼š')
    add_text(doc, '')
    add_text(doc, '                  é æ¸¬')
    add_text(doc, '              æ­£ç¢º    éŒ¯èª¤')
    add_text(doc, 'çœŸå¯¦  æ­£ç¢º     50      10    â† TN=50, FP=10')
    add_text(doc, '      éŒ¯èª¤      5      35    â† FN=5,  TP=35')
    add_text(doc, '')
    add_text(doc, 'â€¢ TN (True Negative)ï¼šæ­£ç¢ºé æ¸¬ç‚ºæ­£ç¢º = 50', bullet=True)
    add_text(doc, 'â€¢ TP (True Positive)ï¼šæ­£ç¢ºé æ¸¬ç‚ºéŒ¯èª¤ = 35', bullet=True)
    add_text(doc, 'â€¢ FP (False Positive)ï¼šèª¤å ±ï¼ˆæ­£ç¢ºèªªæˆéŒ¯èª¤ï¼‰= 5', bullet=True)
    add_text(doc, 'â€¢ FN (False Negative)ï¼šæ¼å ±ï¼ˆéŒ¯èª¤èªªæˆæ­£ç¢ºï¼‰= 10', bullet=True)

    doc.add_heading('18.2 ç†±åœ–ç¹ªè£½', 2)
    code18 = """import seaborn as sns
import numpy as np

# è¨ˆç®—å¹³å‡æ··æ·†çŸ©é™£
avg_cm = np.mean(fold_results['confusion_matrices'], axis=0)

# ç¹ªè£½ç†±åœ–
sns.heatmap(
    avg_cm,
    annot=True,                          # é¡¯ç¤ºæ•¸å­—
    fmt='.1f',                           # æ ¼å¼åŒ–ç‚º 1 ä½å°æ•¸
    cmap='Greens',                       # ç¶ è‰²æ¼¸å±¤
    xticklabels=['Correct', 'Error'],    # X è»¸æ¨™ç±¤
    yticklabels=['Correct', 'Error']     # Y è»¸æ¨™ç±¤
)"""

    add_highlighted_code(doc, code18)

    add_text(doc, 'ã€ç†±åœ–ï¼ˆHeatmapï¼‰ã€‘')
    add_text(doc, 'ç”¨é¡è‰²æ·±æ·ºè¡¨ç¤ºæ•¸å€¼å¤§å°ï¼Œæ•¸å­—è¶Šå¤§é¡è‰²è¶Šæ·±ã€‚')
    add_text(doc, '')
    add_text(doc, 'ã€annot=Trueã€‘åœ¨æ ¼å­è£¡é¡¯ç¤ºæ•¸å­—')
    add_text(doc, "ã€fmt='.1f'ã€‘æ ¼å¼åŒ–ç‚º 1 ä½å°æ•¸ï¼ˆ50.0ï¼‰")
    add_text(doc, "ã€cmap='Greens'ã€‘ä½¿ç”¨ç¶ è‰²ç³»æ¼¸å±¤")

    doc.add_page_break()

    # ========== Cell 19: æŠ˜ç·šåœ– ==========
    add_heading_custom(doc, 'Cell 19: æ€§èƒ½æŒ‡æ¨™è¦–è¦ºåŒ–', 1)

    doc.add_heading('19.1 æŠ˜ç·šåœ–ç¹ªè£½', 2)
    code19 = """import matplotlib.pyplot as plt

folds = [1, 2, 3, 4, 5]
values = [0.85, 0.87, 0.83, 0.86, 0.84]
mean = 0.85
ci_lower, ci_upper = 0.83, 0.87

# ç¹ªè£½æŠ˜ç·šåœ–
ax.plot(folds, values, marker='o', linewidth=2, color='steelblue', label='Fold Results')

# å¹³å‡ç·šï¼ˆæ°´å¹³ç·šï¼‰
ax.axhline(y=mean, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean:.4f}')

# ä¿¡è³´å€é–“ï¼ˆé™°å½±å€åŸŸï¼‰
ax.axhspan(ci_lower, ci_upper, alpha=0.2, color='red', label='95% CI')

# è¨­å®š
ax.set_xlabel('Fold')
ax.set_ylabel('F1 Score')
ax.legend()"""

    add_highlighted_code(doc, code19)

    add_text(doc, 'ã€plotã€‘ç¹ªè£½æŠ˜ç·šåœ–')
    add_text(doc, 'â€¢ marker="o"ï¼šåœ¨è³‡æ–™é»åŠ åœ“åœˆ', bullet=True)
    add_text(doc, 'â€¢ linewidth=2ï¼šç·šæ¢å¯¬åº¦', bullet=True)
    add_text(doc, 'â€¢ color="steelblue"ï¼šé‹¼è—è‰²', bullet=True)
    add_text(doc, '')
    add_text(doc, 'ã€axhlineã€‘ç¹ªè£½æ°´å¹³ç·šï¼ˆå¹³å‡ç·šï¼‰')
    add_text(doc, "â€¢ linestyle='--'ï¼šè™›ç·š", bullet=True)
    add_text(doc, '')
    add_text(doc, 'ã€axhspanã€‘ç¹ªè£½æ°´å¹³ç¯„åœï¼ˆä¿¡è³´å€é–“é™°å½±ï¼‰')
    add_text(doc, 'â€¢ alpha=0.2ï¼šé€æ˜åº¦ 20%ï¼Œè®“é™°å½±ä¸æœƒæ“‹ä½è³‡æ–™', bullet=True)

    doc.add_page_break()

    # ========== Cell 20: å ±å‘Š ==========
    add_heading_custom(doc, 'Cell 20: ç”Ÿæˆè©³ç´°å ±å‘Š', 1)

    doc.add_heading('20.1 å ±å‘Šç”Ÿæˆæµç¨‹', 2)
    code20 = """# å»ºç«‹å ±å‘Šè¡Œ
report_lines = []
report_lines.append('=' * 80)
report_lines.append('MedGemma è¨“ç·´å ±å‘Š')
report_lines.append('=' * 80)
report_lines.append(f'å¹³å‡ F1 Score: {mean:.4f} Â± {std:.4f}')
report_lines.append(f'95% ä¿¡è³´å€é–“: [{ci_lower:.4f}, {ci_upper:.4f}]')

# çµ„åˆæˆå®Œæ•´æ–‡å­—
report_text = '\\n'.join(report_lines)

# å„²å­˜åˆ°æª”æ¡ˆ
with open('cv_report.txt', 'w', encoding='utf-8') as f:
    f.write(report_text)

print('âœ… å ±å‘Šå·²ä¿å­˜')"""

    add_highlighted_code(doc, code20)

    doc.add_heading('20.2 é‡è¦æ¦‚å¿µ', 2)
    add_text(doc, "ã€'=' * 80ã€‘")
    add_text(doc, "å­—ä¸²é‡è¤‡ 80 æ¬¡ï¼Œç”¢ç”Ÿåˆ†éš”ç·šï¼š'===============...==============='")
    add_text(doc, '')
    add_text(doc, "ã€'\\n'.join()ã€‘")
    add_text(doc, 'ç”¨æ›è¡Œç¬¦è™Ÿé€£æ¥ list ä¸­çš„å­—ä¸²ï¼Œçµ„åˆæˆå®Œæ•´æ–‡å­—ã€‚')
    add_text(doc, '')
    add_text(doc, "ã€open('w')ã€‘")
    add_text(doc, 'å¯«å…¥æ¨¡å¼ï¼Œæœƒè¦†è“‹åŸæœ‰å…§å®¹ã€‚å¦‚æœè¦é™„åŠ å…§å®¹ï¼Œç”¨ "a" æ¨¡å¼ã€‚')
    add_text(doc, '')
    add_text(doc, "ã€encoding='utf-8'ã€‘")
    add_text(doc, 'ä½¿ç”¨ UTF-8 ç·¨ç¢¼ï¼Œæ”¯æ´ä¸­æ–‡ã€æ—¥æ–‡ç­‰å¤šåœ‹èªè¨€ã€‚')

    doc.add_page_break()

    # ========== ç¸½çµ ==========
    add_heading_custom(doc, 'å®Œæ•´è¨“ç·´æµç¨‹ç¸½çµ', 1)

    doc.add_heading('20 å€‹ Cells åŠŸèƒ½æ¦‚è¦½', 2)
    add_text(doc, 'Cell 1-2ï¼šç’°å¢ƒè¨­å®šï¼ˆå®‰è£ã€å°å…¥ï¼‰')
    add_text(doc, 'Cell 3-5ï¼šåŸºç¤æº–å‚™ï¼ˆGPUã€Driveã€æª”æ¡ˆï¼‰')
    add_text(doc, 'Cell 6-8ï¼šè³‡æ–™è®€å–èˆ‡æ•´åˆ')
    add_text(doc, 'Cell 9ï¼šè³‡æ–™å¹³è¡¡ï¼ˆè§£æ±ºä¸å¹³è¡¡å•é¡Œï¼‰â­')
    add_text(doc, 'Cell 10-11ï¼šè¨“ç·´æº–å‚™ï¼ˆåƒæ•¸ã€æ ¼å¼è½‰æ›ï¼‰')
    add_text(doc, 'Cell 12-16ï¼šæ¨¡å‹è¨“ç·´ï¼ˆ5-fold äº¤å‰é©—è­‰ï¼‰â­')
    add_text(doc, 'Cell 17ï¼šçµ±è¨ˆåˆ†æï¼ˆå¹³å‡ã€æ¨™æº–å·®ã€ä¿¡è³´å€é–“ï¼‰â­')
    add_text(doc, 'Cell 18-19ï¼šè¦–è¦ºåŒ–ï¼ˆæ··æ·†çŸ©é™£ã€æŠ˜ç·šåœ–ï¼‰')
    add_text(doc, 'Cell 20ï¼šç”Ÿæˆå ±å‘Š')

    doc.add_heading('æ ¸å¿ƒæŠ€è¡“', 2)
    add_text(doc, 'ã€é‡åŒ–ã€‘32-bit â†’ 4-bitï¼Œç¯€çœ 8 å€è¨˜æ†¶é«”')
    add_text(doc, 'ã€LoRAã€‘åªè¨“ç·´ 0.21% åƒæ•¸ï¼Œé€Ÿåº¦å¿« 400 å€')
    add_text(doc, 'ã€äº¤å‰é©—è­‰ã€‘5-foldï¼Œçµæœæ›´å¯é ')
    add_text(doc, 'ã€è³‡æ–™å¹³è¡¡ã€‘è§£æ±ºä¸å¹³è¡¡å•é¡Œï¼Œæå‡æ¨¡å‹è¡¨ç¾')

    doc.add_heading('ä½ å­¸åˆ°äº†ä»€éº¼ï¼Ÿ', 2)
    add_text(doc, '1. Python åŸºç¤ï¼šè®Šæ•¸ã€å‡½æ•¸ã€è¿´åœˆã€æ¢ä»¶åˆ¤æ–·')
    add_text(doc, '2. è³‡æ–™è™•ç†ï¼šPandasã€Excelã€è³‡æ–™å¹³è¡¡')
    add_text(doc, '3. æ©Ÿå™¨å­¸ç¿’ï¼šè¨“ç·´/æ¸¬è©¦é›†ã€äº¤å‰é©—è­‰ã€è©•ä¼°æŒ‡æ¨™')
    add_text(doc, '4. æ·±åº¦å­¸ç¿’ï¼šé‡åŒ–ã€LoRAã€è¨“ç·´éç¨‹')
    add_text(doc, '5. çµ±è¨ˆåˆ†æï¼šå¹³å‡å€¼ã€æ¨™æº–å·®ã€ä¿¡è³´å€é–“')
    add_text(doc, '6. è³‡æ–™è¦–è¦ºåŒ–ï¼šç†±åœ–ã€æŠ˜ç·šåœ–ã€Matplotlib/Seaborn')
    add_text(doc, '7. æª”æ¡ˆæ“ä½œï¼šè®€å–ã€å¯«å…¥ã€è·¯å¾‘è™•ç†')

    add_text(doc, '')
    add_text(doc, '')
    p = doc.add_paragraph('æ­å–œä½ å®Œæˆäº†å®Œæ•´çš„ MedGemma è¨“ç·´æ•™å­¸ï¼ğŸ‰')
    p.alignment = WD_ALIGN_PARAGRAPH.CENTER
    for run in p.runs:
        run.font.size = Pt(14)
        run.bold = True
        run.font.color.rgb = RGBColor(0, 100, 0)

    return doc

# ========== ä¸»ç¨‹å¼ ==========
if __name__ == '__main__':
    print("=" * 80)
    print("æ­£åœ¨ç”Ÿæˆå¸¶æœ‰èªæ³•é«˜äº®çš„è¨“ç·´æ–‡ä»¶...")
    print("=" * 80)
    print()

    doc = create_document()

    # å„²å­˜ Word æ–‡ä»¶
    output_path = '/home/user/my-colab-notebooks/MedGemma_è¨“ç·´æ•™å­¸_èªæ³•é«˜äº®ç‰ˆ.docx'
    doc.save(output_path)

    file_size = os.path.getsize(output_path) / 1024
    print(f"âœ… Word æ–‡ä»¶å·²ç”Ÿæˆ: {output_path}")
    print(f"ğŸ“„ æª”æ¡ˆå¤§å°: {file_size:.2f} KB")
    print()
    print("=" * 80)
    print("æ–‡ä»¶ç‰¹è‰²ï¼š")
    print("â€¢ ç¨‹å¼ç¢¼æœ‰èªæ³•é«˜äº®ï¼ˆä¸åŒé¡è‰²ï¼‰")
    print("â€¢ é—œéµå­—ï¼šç´«è‰²")
    print("â€¢ å­—ä¸²ï¼šæ©˜è‰²")
    print("â€¢ è¨»è§£ï¼šç¶ è‰²")
    print("â€¢ å‡½æ•¸åï¼šæ·ºé»ƒè‰²")
    print("â€¢ æ•¸å­—ï¼šæ·ºç¶ è‰²")
    print("=" * 80)
